[{"content":"碎碎念 在 Springboot 中，跨服务的文件传输需要考虑性能、一致性、安全性等问题。\n对于 Excel 文件的上传下载，是否在对外服务层进行解析和封装会更好呢？\n对于其他类型的文件，可以考虑独立出一个文件服务，以实现服务解耦和更好的水平扩展。\n01 SpringBoot 图片上传 普通文件上传 普通的文件上传，直接使用 MultipartFile 类型声明参数即可：\n@RestController public class FileUploadController { @PostMapping(\u0026#34;/upload\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; handleFileUpload( @RequestParam(\u0026#34;file\u0026#34;) MultipartFile file, @RequestParam(\u0026#34;param1\u0026#34;) String param1, @RequestParam(\u0026#34;param2\u0026#34;) String param2) { if (file.isEmpty()) { return ResponseEntity.badRequest().body(\u0026#34;请选择文件上传\u0026#34;); } // 这里可以添加文件上传的业务逻辑，比如保存文件到服务器 return ResponseEntity.ok(\u0026#34;文件上传成功\u0026#34;); } } 如果是多文件上传，则使用 MultipartFile[] 数组。\n如果参数过多，可以使用 @SpringQueryMap 把参数放在类里面，这是 OpenFeign 提供的类似 @QueryMap 功能，支持把 Query 参数封装到对象中：\n@RestController public class FileUploadController { @PostMapping(\u0026#34;/upload\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; handleFileUpload( @RequestParam(\u0026#34;file\u0026#34;) MultipartFile file, @Validated @SpringQueryMap QueryDTO req) { // do sth. } } 02 OpenFeign 文件上传 当从对外的 Web 服务把文件传到 OpenFeign 的服务时，MultipartFile 需要使用 @RequestPart 而非 @RequestParam，请求头 content-type 为 multipart/form-data，否则会报错：\norg.springframework.web.multipart.MultipartException:Current request is not a multipart request\u0026hellip;\n@FeignClient(name = \u0026#34;OK-productor\u0026#34;, fallback = RenderApiFallback.class) public interface RenderApi { @PostMapping(value = \u0026#34;/upload\u0026#34;, consumes = MediaType.MULTIPART_FORM_DATA_VALUE) ResponseObject upload(@RequestPart(\u0026#34;file\u0026#34;) MultipartFile file); } 至于对外的 web 服务或者内部 OpenFiegn 调用的服务，使用 @RequestPart 或者 @RequestParam，只要前端支就都能正常调用。\n问题分析 graph LR;\rclient --\u0026gt; |http| Web --\u0026gt;|feign| A; Q.1 Feign 仅用 @RequestParam 注解 MultipartFile // Web @PostMapping(\u0026#34;/upload\u0026#34;) public R upload(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) { return aApi.upload(file); } // Feign interface @PostMapping(\u0026#34;/server-a/upload\u0026#34;) R upload(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file); // A @PostMapping(\u0026#34;/upload\u0026#34;) R upload(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) {} // or R upload(@RequestPart(\u0026#34;file\u0026#34;) MultipartFile file) {} A 服务报错：Required request part \u0026lsquo;file\u0026rsquo; is not present。\nQ.2 Feign 仅用 @RequestPart 注解 MultipartFile 针对 Q.1 的问题，将 RequestParam 改为 RequestPart：\n// Web @PostMapping(\u0026#34;/upload\u0026#34;) public R upload(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) { return aApi.upload(file); } // Feign interface // RequestParam 改为 RequestPart @PostMapping(\u0026#34;/server-a/upload\u0026#34;) R upload(@RequestPart(\u0026#34;file\u0026#34;) MultipartFile file); // A @PostMapping(\u0026#34;/upload\u0026#34;) R upload(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) {} // or R upload(@RequestPart(\u0026#34;file\u0026#34;) MultipartFile file) {} Feign 调用直接熔断，无法连接 A 服务。\nQ.3 Feign 使用 @RequestPart 注解 MultipartFile，并且添加 consume 类型 仅用 @RequestPart 注解 MultipartFile 会导致熔断，应该是接口对不上，而通过 postman 上传的请求头是 form-data 类型的，所以改为一致再试试：\n// Web @PostMapping(\u0026#34;/upload\u0026#34;) public R upload(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) { return aApi.upload(file); } // Feign interface // RequestParam 改为 RequestPart // 添加 form-data 类型 @PostMapping(value = \u0026#34;/server-a/upload\u0026#34;, consumes = MediaType.MULTIPART_FORM_DATA_VALUE) R upload(@RequestPart(\u0026#34;file\u0026#34;) MultipartFile file); // A @PostMapping(\u0026#34;/upload\u0026#34;) R upload(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) {} // or R upload(@RequestPart(\u0026#34;file\u0026#34;) MultipartFile file) {} consumes: 指定处理请求的提交内容类型（Content-Type） 当 Feign 使用 @RequestPart 注解 MultipartFile，并且指定 consume 类型为 multipart/form-data，可以正常传输文件！\nQ.4 A 服务时好时坏 在 Feign 接口中使用了 @RequestPart 注解，配和 consumes = \u0026quot;multipart/form-data\u0026quot;，已经可以正常通过 Feign 调用传输文件了。\n但是，在测试过程中发现 A 服务时好时坏，报错：Required request part 'file' is not present，这是为什么呢？\n后来发现，在调用 Feign 接口时，拦截器默认给所有请求添加了 Content-Type: application/json，而 Feign 调用时本身就加上了 content-type: multipart/form-data：\n@Configuration public class FeginInterceptor implements RequestInterceptor { @Override public void apply(RequestTemplate template) { Map\u0026lt;String,String\u0026gt; headers = getHeaders(getHttpServletRequest()); for(String headerName : headers.keySet()){ String headerValue; if(\u0026#34;content-type\u0026#34;.equals(headerName)){ headerValue = \u0026#34;application/json;charset=UTF-8\u0026#34;; // 修改：跳过 content-type，不再添加该请求头，使用默认头即可 // continue; }else { headerValue = getHeaders(getHttpServletRequest()).get(headerName); } template.header(headerName, headerValue); } } } 其中，template.header(headerName, headerValue) 的操作是追加（append），而不是添加（代码位置 feign.RequestTemplate#appendHeader）：\nprivate RequestTemplate appendHeader(String name, Iterable\u0026lt;String\u0026gt; values) { if (!values.iterator().hasNext()) { this.headers.remove(name); return this; } else { this.headers.compute(name, (headerName, headerTemplate) -\u0026gt; { // 这里执行的是 HeaderTemplate.append // 原值：Content-Type multipart/form-data; charset=UTF-8; boundary=18e89936153 // 追加：Content-Type multipart/form-data; charset=UTF-8; boundary=18e89936153, application/json;charset=UTF-8 return headerTemplate == null ? HeaderTemplate.create(headerName, values) : HeaderTemplate.append(headerTemplate, values); }); return this; } } 经过拦截器的追加之后，准备请求 Feign 时，可以看到 Content-Type 是两个值，也就是上面的 multipart/form-data 和 application/json;charset=UTF-8（代码位置 feign.SynchronousMethodHandler#executeAndDecode）\n在调用前，获取到的 RibbonRequest 还是那两个请求头，类型为 UnmodifiableRandomAccessList（代码位置 org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient#execute） Object executeAndDecode(RequestTemplate template) throws Throwable { Request request = this.targetRequest(template); long start = System.nanoTime(); Response response; try { response = this.client.execute(request, this.options); } // ... } 从多次观察 feign.SynchronousMethodHandler#executeAndDecode 中 client 的请求结果，可以看出，只要 Content-Type 这个随机数组的第一个请求头是 multipart/form-data，请求就成功。\n也就是说，项目的 Feign 自动添加了请求头（只考虑 json 格式），导致其他的请求会带上多个一样的请求头，真正的请求用到的是请求头数组的第一个，而请求头数组是随机的，导致请求时而成功，时而失败。\n所以，如果项目中添加了 Feign 的拦截配置，当请求头是 Content-Type 是，直接跳过即可。\n为什么要给 Feign 添加 json 类型的 content-type？\n我猜原本的 Feign 配置是为了给一些没有带 Content-Type 请求头或者带其他格式请求头的请求都统一转为 json，但没有考虑到文件传输的问题。原本的文件传输接口，直接在 Web 服务实现的，它是通用上传接口，在 Web 服务实现并没有什么问题，也省去了中间服务调用的损耗。还有一种就是文件传输到 Web，直接解析成参数再调用相应的服务，这也不需要在服务间传递文件。但是，部分特殊的需求，如传输二进制文件、压缩包等，并且需要使用到相应服务的数据库资源等，在相应的服务操作是比较合适的。\nReferences [1] HE-RUNNING. Feign 传输 Multipartfile 文件的正确方式，Current request is not a multipart request 报错解决. https://blog.csdn.net/weishaoqi2/article/details/106479476, 2020-06-01.\n[2] 哈哈哈哈哈基米. 关于 openfeign 调用时 content-type 的问题. https://blog.csdn.net/ssH18868325485/article/details/132339361, 2023-08-17.\n","permalink":"https://blog.springx.fun/posts/tech/java-springboot-file-upload-download/","summary":"碎碎念 在 Springboot 中，跨服务的文件传输需要考虑性能、一致性、安全性等问题。\n对于 Excel 文件的上传下载，是否在对外服务层进行解析和封装会更好呢？\n对于其他类型的文件，可以考虑独立出一个文件服务，以实现服务解耦和更好的水平扩展。\n01 SpringBoot 图片上传 普通文件上传 普通的文件上传，直接使用 MultipartFile 类型声明参数即可：\n@RestController public class FileUploadController { @PostMapping(\u0026#34;/upload\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; handleFileUpload( @RequestParam(\u0026#34;file\u0026#34;) MultipartFile file, @RequestParam(\u0026#34;param1\u0026#34;) String param1, @RequestParam(\u0026#34;param2\u0026#34;) String param2) { if (file.isEmpty()) { return ResponseEntity.badRequest().body(\u0026#34;请选择文件上传\u0026#34;); } // 这里可以添加文件上传的业务逻辑，比如保存文件到服务器 return ResponseEntity.ok(\u0026#34;文件上传成功\u0026#34;); } } 如果是多文件上传，则使用 MultipartFile[] 数组。\n如果参数过多，可以使用 @SpringQueryMap 把参数放在类里面，这是 OpenFeign 提供的类似 @QueryMap 功能，支持把 Query 参数封装到对象中：\n@RestController public class FileUploadController { @PostMapping(\u0026#34;/upload\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; handleFileUpload( @RequestParam(\u0026#34;file\u0026#34;) MultipartFile file, @Validated @SpringQueryMap QueryDTO req) { // do sth.","title":"SpringBoot 关于文件的上传与下载"},{"content":"问题是什么呢？ 在停止 Tomcat 后，无法再次启动。\n尝试使用 catalina.sh 启动时出现如下警告：\n[R@K tomcat/bin]$ ./catalina.sh start Using CATALINA_BASE: /app/tomcat Using CATALINA_HOME: /app/tomcat Using CATALINA_TMPDIR: /app/tomcat/temp Using JRE_HOME: /app/j2sdk1.8.0/jre Using CLASSPATH: /app/tomcat/bin/bootstrap.jar:/app/tomcat/bin/tomcat-juli.jar Using CATALINA_OPTS: -javaagent:/app/skywalking/skywalking-agent/skywalking-agent.jar -Dskywalking.agent.service_name=springx-web -Dskywalking.collector.backend_service=192.168.1.122:11800 Using CATALINA_PID: /app/tomcat/bin/CATALINA_PID Existing PID file found during start. Tomcat appears to still be running with PID 22832. Start aborted. # 这里说 Tomcat 已经运行了，PID 为 22832 If the following process is not a Tomcat process, remove the PID file and try again: UID PID PPID C STIME TTY TIME CMD # 可是这里并没有任何进程 输出的日志显示，PID 已存在。根据部分 Linux 应用的习惯可知，Tomcat 启动后，会将其 PID 记录在一个文件中，再次启动时会主动检测该文件，以判断是否重复启动。\n日志还输出了 ps 命令的结果，可见并没有 PID 为 22832 的进程。\n而通过 ps -ef | grep java 也没有找到任何进程，明明 Tomcat 已经停止了，为什么说已经在运行了呢？\n寻找原因 猜测原因是，Tomcat 停止时由于 JDBC 等其他线程未正常停止，导致 Tomcat 没有正常停止，在二次执行 kill -9 后，出现意外。\n这里为什么会使用 kill -9 呢？年代久远，无从可考。原脚本是使用 catalina.sh stop，但却在 sleep 几秒之后，使用 kill -9 杀死 java 相关进程。 这里大胆猜测，前辈在停止 Tomcat，经常未能正常停止，所以选择几秒之后直接强杀。\n解决问题 在 Tomcat 的 bin 目录下，有一个 CATALINA_PID? 文件，它就是记录 PID 的文件（上述日志有体现）。\n[R@K tomcat/bin]$ ls catalina64.bat catalina.bat ciphers.bat catalina64.sh CATALINA_PID? # ←就是这个文件 # ... catalina64.sh.default catalina.sh catalinabak.sh catalina-tasks.xml [R@K tomcat/bin]$ [R@K tomcat/bin]$ cat CATALINA_PID^M 22832 [R@K tomcat/bin]$ rm CATALINA_PID^M 查看该文件的内容，确实是日志报错的 PID。\n把该文件删除，可以正常启动 Tomcat 了。并且可以看到该文件被重新生成，并附上了新的 Tomcat PID：\n[R@K tomcat/bin]$ cat CATALINA_PID^M 1369 碎碎念 会出现以上问题，主要是项目没有、并且不能优雅的停止，导致用上了强杀的手段。\n这个项目的可考记录，可以追溯到 0 几年，很多代码没人敢动，旧代码单文件动不动就是几千行，最近头发掉了不少。\n","permalink":"https://blog.springx.fun/posts/tech/tomcat-appears-to-still-be-running-with-pid/","summary":"问题是什么呢？ 在停止 Tomcat 后，无法再次启动。\n尝试使用 catalina.sh 启动时出现如下警告：\n[R@K tomcat/bin]$ ./catalina.sh start Using CATALINA_BASE: /app/tomcat Using CATALINA_HOME: /app/tomcat Using CATALINA_TMPDIR: /app/tomcat/temp Using JRE_HOME: /app/j2sdk1.8.0/jre Using CLASSPATH: /app/tomcat/bin/bootstrap.jar:/app/tomcat/bin/tomcat-juli.jar Using CATALINA_OPTS: -javaagent:/app/skywalking/skywalking-agent/skywalking-agent.jar -Dskywalking.agent.service_name=springx-web -Dskywalking.collector.backend_service=192.168.1.122:11800 Using CATALINA_PID: /app/tomcat/bin/CATALINA_PID Existing PID file found during start. Tomcat appears to still be running with PID 22832. Start aborted. # 这里说 Tomcat 已经运行了，PID 为 22832 If the following process is not a Tomcat process, remove the PID file and try again: UID PID PPID C STIME TTY TIME CMD # 可是这里并没有任何进程 输出的日志显示，PID 已存在。根据部分 Linux 应用的习惯可知，Tomcat 启动后，会将其 PID 记录在一个文件中，再次启动时会主动检测该文件，以判断是否重复启动。","title":"Tomcat 停止后无法启动，“Tomcat appears to still be running with PID ...”"},{"content":"00 碎碎念 为什么使用 Docker 去搭建 Jenkins 呢？\n主要原因是个人频繁切换环境，有时候在本地虚拟机玩，有时候会在云服务器上折腾，渐感被自己折磨过多了，因此希望能够创建一个配置文件，以便一键启动并快速方便地使用。另外，自己经常在其他地方装环境，公司的服务也比较老，一但要迁移，用 Docker 就很方便。所以，使用 Docker 是很适合的。\n网上那么多一样的文章，为什么要写这篇呢？\n虽然说这篇文章是作为笔记的，但是因为自己在使用网上的方法安装的时候，遇到几个问题，尝试了很多方法才成功，所以想要记录一下，以备不时之需。\n01 Docker Compose 安装 以下是测试过的，能正常部署和使用 Jenkins 的 Docker Compose 配置，部分参数请按需调整。\nversion: \u0026#39;3.9\u0026#39; services: jenkins: # 镜像选择了 jdk17 最新版，可自行选择 image: jenkins/jenkins:jdk17 container_name: jenkins # 重启策略：除非手动停止，否则出错会无限重启 restart: unless-stopped # 指定用户 uid:gid（`用户id`:`宿主机的docker组id`，跟文件权限有关） user: 1000:995 ports: # 8080 为 Jenkins 的 Web 端口 - 9001:8080 # 50000 为代理节点与主服务器的通信端口？ - 50001:50000 volumes: # 同步宿主机的时间 - /etc/timezone:/etc/timezone - /etc/localtime:/etc/localtime # Jenkins 数据目录映射出来，方面操作和备份 - .jenkins_home:/var/jenkins_home # 把宿主机的 docker 和 docker-compose 给 Jenkins 使用，这样可以直接在 Jenkins 内部打镜像，并直接操作容器 - /usr/bin/docker:/usr/bin/docker - /var/run/docker.sock:/var/run/docker.sock - /usr/local/bin/docker-compose:/usr/local/bin/docker-compose 使用 Docker Compose 直接启动即可：\n# -d：后台启动 $ docker-compose up -d # 1. 查看日志，临时登录密码会放到文件中，也会直接打在日志上 # 临时密码位置：/var/jenkins_home/secrets/initialAdminPassword # 2. 或使用 docker 命令查看： docker logs jenkins $ docker-compose logs -f Jenkins initial setup is required.An admin user has been created and a password generated. Please use the following password to proceed to installation: # 临时密码 57ea14a04f9464d895655348d6ad6a86 然后，访问 9001（这里已经映射为 9001 端口了）：http://ip:9001，输入临时密码登录。\n接着，选择安装插件，创建用户，等待完成即可。（这些步骤都可以跳过，后续再进行即可）\n02 问题及解决办法 2.1 Docker 权限问题（Permission denied） 用网上的方法，折腾了好久……\n把 Docker 相关文件映射到容器内部后，会遇到权限问题（如果直接指定 root 用户部署，不会有权限问题！），网上有许多把 jenkins 用户添加到 docker 组的方式，但这依然是基于宿主机的环境，未必能直接解决。\n我比较爱折腾，环境稍微有差异，直接把 jenkins 用户添加到 docker 组依然有权限问题，接下来看看具体的情况和处理方法。\n事情是这样子的~\n首先，来看看 docker.sock 在 Jenkins 容器内部的情况：\njenkins@b0e6d3e8ce07:~$ ls -l /var/run/ | grep docker srw-rw----. 1 root 998 0 Jun 3 01:59 docker.sock docker.sock 是我们从宿主机映射到容器内的 sock 文件，它是 Docker 守护进程（Docker daemon）与 Docker 客户端之间进行通信的 UNIX 套接字文件（UNIX socket file）。\n由于 docker 相关文件是属于宿主机的，原则上不直接修改它，而是通过修改容器来兼容。但是，这里的 sock 属于 root 用户，如果使用普通用户（默认 jenkins:1000）部署，并没有权限去读取。\n998 是 docker 组的组 id（gid），网上找到比较好的方法是，把 jenkins 用户直接加入该组，就可以正常使用宿主机 docker 了。\n而我的问题就出在这里。\n先用网上的方法试试？\n接着，来看下容器内部的情况：\njenkins@b0e6d3e8ce07:~$ id jenkins uid=1000(jenkins) gid=1000(jenkins) groups=1000(jenkins) jenkins@b0e6d3e8ce07:~$ id uid=1000(jenkins) gid=995 groups=995 # 下面是配置 `user: root` 部署的，容器内部使用 root 用户，可以正常使用 docker root@8900354a95f1:/# id uid=0(root) gid=0(root) groups=0(root) 第一个命令，id jenkins 表明 jenkins 用户的用户 id 和组 id 都为 1000；\n第二个命令，id 表明当前登录会话的用户 id 为 1000，而组 id 和 groups 为 995（为什么不一样？因为 docker-compose 配置文件设置的，groups 就是重点）。\n也就是说，当前登录会话的用户，既不是 root 用户，也不属于 998 组，所有没有权限读取 docker.sock。\n所以，到这儿得先把 jenkins 加入 998 组，否则不可能有权限的。这个 docker 组应该不存在，我们需要先创建该组，然后再把 jenkins 加入：\n# 先退出容器，使用 root 登录（-u 指定登录用户） $ sudo docker exec -it -u root jenkins bash # 然后，创建 docker 组，指定与 docker.sock 一样的组 id # groupadd -g \u0026lt;gid\u0026gt; \u0026lt;group_name\u0026gt; $ groupadd -g 998 docker # 最后，把 jenkins 加入该组 # usermod -a -G \u0026lt;group_name\u0026gt; \u0026lt;username\u0026gt; $ usermod -aG docker jenkins 到这一步，我还是没有权限，重启容器也没有用，这是为什么呢？\n一路走到黑？\n折腾了很久都没效果，本来已经要放弃了，就在宿主机试验了一遍：docker 组已经存在，把普通用户加入 docker，重新登录，普通用户居然有权限了！\n[springx@** ~]$ id uid=1000(springx) gid=1000(springx) groups=1000(springx),995(docker) context=un... 可以看出，在宿主机中，当前登录的用户的会话是包含 docker 组的（groups = 1000，995，宿主机的 docker 组 id 正好为 995）。\n相反的是，在容器内部，即使修改了用户组，登录会话的组还是 docker-compose 配置的 995（groups），所以怎么试都没有权限。\n找到问题的根源：有没有权限，与登录会话有关，需要拥有 docker 组的权限才可以。\n既然知道了问题的根源，那如何让登录会话拥有 docker 组权限呢？\n临时测试方法（newgrp）\n想要修改登录会话所属组，就要修改登录身份。也就是说，用户以哪个组的身份登录，就拥有对应组的权限。\n我们可以通过 newgrp 临时切换到 docker 组，来测试 jenkins 用户是否有权限使用 docker：\n$ newgrp docker $ id uid=1000(jenkins) gid=995 groups=998 $ docker version # ... OK！ 从上面的切换方式可以看出，jenkins 已经有了权限，但是重新登录后，又会回到原来的组，而且仅仅是当前切换后的会话才有权限，在项目中使用 docker 还是没有权限的。\n永久解决\n既然修改登录的组，就能获取权限，那该如何彻底解决呢？\n前面提到，docker-compose 配置了用户 id 和组 id，这将会使用户以该配置的运行，所以，我们只需要把组 id 指定为和宿主机一样的 docker 组 id 即可。\n从最前面给出的 docker-compose 配置文件，可以看出给 user 的配置是 1000:995，1000 是宿主机的用户，Jenkins 是该用户部署的，默认用户是 jenkins（1000），配置一样的 id，可以避免映射处理的文件的读写权限问题；995 是宿主机 docker 的组 id，这样容器内部的用户就会以 1000：955 的身份登录。\n# 宿主机的 docker 组 id $ cat /etc/group | grep docker docker:x:995:springx 小结\n对于容器内的 Jenkins，想要使用宿主机的 docker，只需要在 docker-compose.yaml 中配置 user，指定宿主机 docker 组 id 即可，并不需要在容器内创建 docker 组（实际 Jenkins 容器内并不存在 995 的组，但这并不影响）\nversion: \u0026#39;3.9\u0026#39; services: jenkins: image: jenkins/jenkins:jdk17 container_name: jenkins # 指定用户 uid:gid（`用户id`:`docker组id`，跟文件权限有关） # 只要 995 这个值与宿主机的 docker 组 id（使用 `cat /etc/group | grep docker` 查看）一致即可！ user: 1000:995 2.2 映射目录权限问题 映射到宿主机的目录和文件，同样会遇到权限问题，这个与上面 docker 权限问题相比简单至极。\n要么，开放映射目录（.jenkins_home）的所有权限。（这样似乎不太好？反正我感觉不好，但我没证据~）\n$ chmod 777 .jenkins_home 要么，切换映射目录的归属。例如，我使用普通用户 springx（1000:1000）部署 Jenkins，目录所有者就是 1000，刚好 Jenkins 容器内部默认用户 jenkins 也是 1000:1000，所以，只要用 springx 用户先创建 .jenkins_home，然后配置 docker-compose 指定 user: 1000:gid 即可。\n[springx@fun ~]$ mkdir .jenkins_home # 如果使用其他用户创建，需要修改权限 [springx@fun ~]$ chwon 1000:1000 .jenkins_home 如果没有提前创建 .jenkins_home，它的默认所有者是 root，此时如果使用普通用户部署（就如上诉使用 1000 用户部署），容器内部的用户是没有权限的：\n$ docker-compose up [+] Running 2/1 ✔ Network jenkins2_default Created ✔ Container jenkins2 Created Attaching to jenkins2 jenkins2 | touch: cannot touch \u0026#39;/var/jenkins_home/copy_reference_file.log\u0026#39;: Permission denied jenkins2 | Can not write to /var/jenkins_home/copy_reference_file.log. Wrong volume permissions? jenkins2 exited with code 0 这里 /var/jenkins_home 映射到了 .jenkins_home 如果配置了重启策略 restart: unless-stopped，只需要修改 chown springx:springx .jenkins_home，然后等待重启即可。 如果执行 docker-compose 的命令是我的普通用户 springx，那么 .jenkins_home 是会有权限的，只不过我没有把 springx 用户加入 docker 组，而是用 sudo 执行的 小结\n如果使用 root 用户部署，映射目录不会有权限问题；如果使用普通用户部署，需要先创建映射目录，并配置相应的权限，否则自动创建的映射目录，属于执行执行创建命令的用户所有，如果用户 id 不一致，会出现无法写入的问题（我用的 sudo，则创建的文件的所有者都是 root）。\n总结 使用 docker-compose 部署 Jenkins，主要涉及几个权限问题，其中主要的是 docker 权限和映射目录的权限：\ndocker 权限可以使用 root 部署，或者修改 docker.sock 权限（不建议）；也可以通过配置，把容器内部的用户，添加到和宿主机 docker 组一样的 id 组即可（user: 1000:995）。\n映射目录权限，可以先手动创建，然后分配给相应的用户，并且 docker-compose 配置对应的用户 id 即可；也可以创建后，再修改权限，等待容器自动重启即可。\n","permalink":"https://blog.springx.fun/posts/tech/docker-compose-install-jenkins/","summary":"00 碎碎念 为什么使用 Docker 去搭建 Jenkins 呢？\n主要原因是个人频繁切换环境，有时候在本地虚拟机玩，有时候会在云服务器上折腾，渐感被自己折磨过多了，因此希望能够创建一个配置文件，以便一键启动并快速方便地使用。另外，自己经常在其他地方装环境，公司的服务也比较老，一但要迁移，用 Docker 就很方便。所以，使用 Docker 是很适合的。\n网上那么多一样的文章，为什么要写这篇呢？\n虽然说这篇文章是作为笔记的，但是因为自己在使用网上的方法安装的时候，遇到几个问题，尝试了很多方法才成功，所以想要记录一下，以备不时之需。\n01 Docker Compose 安装 以下是测试过的，能正常部署和使用 Jenkins 的 Docker Compose 配置，部分参数请按需调整。\nversion: \u0026#39;3.9\u0026#39; services: jenkins: # 镜像选择了 jdk17 最新版，可自行选择 image: jenkins/jenkins:jdk17 container_name: jenkins # 重启策略：除非手动停止，否则出错会无限重启 restart: unless-stopped # 指定用户 uid:gid（`用户id`:`宿主机的docker组id`，跟文件权限有关） user: 1000:995 ports: # 8080 为 Jenkins 的 Web 端口 - 9001:8080 # 50000 为代理节点与主服务器的通信端口？ - 50001:50000 volumes: # 同步宿主机的时间 - /etc/timezone:/etc/timezone - /etc/localtime:/etc/localtime # Jenkins 数据目录映射出来，方面操作和备份 - .","title":"使用 Docker-Compose 搭建 Jenkins"},{"content":"碎碎念 由于网络原因，我们不得不使用一些手段，以疏通或者加速它。\n在 CMD/PowerShell 终端配置代理，可以允许整个命令行得到代理。\n使用 git config 配置代理，则仅支持 git 自身获得代理。\nCMD 设置代理 Windows 的 cmd 使用 set 命令来配置：\n\u0026gt; set http_proxy=http://127.0.0.1:1080 # Or \u0026gt; set https_proxy=https://127.0.0.1:1080 这种方式，可以进行终端全局的代理。\nWindows 还有 PowerShell 终端，也是类似的。\nPowerShell 设置代理 PowerShell 配置方式比较特殊，但同样是设置全局变量 HTTP_PROXY/HTTPS_PROXY（不区分大小写）：\n\u0026gt; $env:HTTP_PROXY=\u0026#34;http://127.0.0.1:1080\u0026#34; # Or \u0026gt; $env:HTTPS_PROXY=\u0026#34;https://127.0.0.1:1080\u0026#34; 注： 终端配置的方式，每次关闭之后，都要重新配置。除了写一段初始化脚本，还可以直接配置 git 的全局代理。\nGit Bash 设置代理 在 Git Bash 中，可以通过 git config 设置 HTTP 代理：\n\u0026gt; git config --global http.proxy \u0026#34;http://127.0.0.1:1080\u0026#34; # Or \u0026gt; git config --global https.proxy \u0026#34;https://127.0.0.1:1080\u0026#34; 但是，这种方式仅适用于 HTTP/HTTPS，不适用于 SSH 方式（即 git clone git@github.com:username/repo.git）。\n如果要使用 SSH 方式通信，需要配置 Git 的 ~/.ssh/config。\n注意\n直接配置 git 的代理，会永久保存，所有 git 连接都走代理。如果代理服务器不在线，会导致 git 无法推送/拉取，需要重置代理配置：\n\u0026gt; git config --global --unset http.proxy SSH 方式代理配置 使用 https 的方式有个缺点，就是输入账号密码，而使用 ssh 方式可以自动使用密钥验证。\n打开 ~/.ssh/config 添加配置（不存在则创建一个）：\nHost github.com\rUser Spring # 用户名\rIdentityFile \u0026#34;C:\\Users\\springx\\.ssh\\id_rsa\u0026#34; # 私钥\rProxyCommand \u0026#34;D:\\OpenSSH-Win64\\bin\\nc.exe\u0026#34; -X 5 -x 127.0.0.1:1080 %h %p # 连接代理 ProxyCommand 是 OpenSSH 配置文件中用于指定在建立 SSH 连接时，通过代理服务器进行连接的命令。它允许你在 SSH 客户端和 SSH 服务器之间建立一个额外的中间连接，通过该中间连接来传输 SSH 流量。\n这里使用 nc（ncat - Concatenate and redirect sockets） 网络工具，CentOS 直接安装 nc，Ubuntu 是 netcat，Windows 下可以安装 OpenSSH，或者借用其他程序携带的 nc.exe（我使用的是 MobaXterm 内置的 nc.exe）\nX：socks 版本号（代理服务器的类型，常见的类型包括 http、https 和 socks5） HTTPS：没有连接，暂时无法验证 HTTP：ProxyCommand nc -X connect -x \u0026lt;HOST\u0026gt;:\u0026lt;PORT\u0026gt; %h %p （不用 -X 参数可以连接，未验证） x：指定代理服务器 ip 和端口号 %h %p：变量，分别表示 github 的 host 和 ssh 端口号（默认 22） Linux 在 Linux 中为命令行设置代理，与 Windows 的 CMD 方式一致：\n\u0026gt; export http_proxy=http://127.0.0.1:1080 # Or \u0026gt; export https_proxy=https://127.0.0.1:1080 QA? 仅设置 http 代理就可以正常访问 https，这是代理本身提供 http 的原因？ 这里的 HTTP 代理并不是指要代理 HTTP 协议的请求，而是指数据从软件（浏览器）到代理客户端的通信方式，本机的代理客户端开启的连接方式为 HTTP，这中间的数据是明文传输的，有被泄露的风险。\n而 HTTPS 代理的核心思路，就是使用 https/tls 对浏览器到代理这一段的通信进行加密，这样中间节点就不能监听数据。\n这里参考：“允许来自局域网的连接” 到底怎么用\nReferences [1] FrozenMap. 为 git bash 设置代理. https://jjayyyyyyy.github.io/2019/08/11/git_bash_proxy.html, 2019-08-11.\n[2] 咕咕. ssh 的高级用法 - ProxyCommand. https://bugwz.com/2019/10/09/ssh-proxycommand/, 2019-10-09.\n- 2023-12-05 edited -\n","permalink":"https://blog.springx.fun/posts/tech/proxy-for-terminal-and-git/","summary":"碎碎念 由于网络原因，我们不得不使用一些手段，以疏通或者加速它。\n在 CMD/PowerShell 终端配置代理，可以允许整个命令行得到代理。\n使用 git config 配置代理，则仅支持 git 自身获得代理。\nCMD 设置代理 Windows 的 cmd 使用 set 命令来配置：\n\u0026gt; set http_proxy=http://127.0.0.1:1080 # Or \u0026gt; set https_proxy=https://127.0.0.1:1080 这种方式，可以进行终端全局的代理。\nWindows 还有 PowerShell 终端，也是类似的。\nPowerShell 设置代理 PowerShell 配置方式比较特殊，但同样是设置全局变量 HTTP_PROXY/HTTPS_PROXY（不区分大小写）：\n\u0026gt; $env:HTTP_PROXY=\u0026#34;http://127.0.0.1:1080\u0026#34; # Or \u0026gt; $env:HTTPS_PROXY=\u0026#34;https://127.0.0.1:1080\u0026#34; 注： 终端配置的方式，每次关闭之后，都要重新配置。除了写一段初始化脚本，还可以直接配置 git 的全局代理。\nGit Bash 设置代理 在 Git Bash 中，可以通过 git config 设置 HTTP 代理：\n\u0026gt; git config --global http.proxy \u0026#34;http://127.0.0.1:1080\u0026#34; # Or \u0026gt; git config --global https.","title":"如何为终端或 Git 设置代理？"},{"content":"01 搭建私服的初衷 1.1 为什么搭建私服？ 使用 Maven 管理项目依赖时，通常会从 Maven 仓库拉取第三方依赖，此时只需要配置公共仓库源即可。\n但是，如果需要使用公司内部依赖，需要同时使用第三方依赖和私有依赖，这就需要搭建私服，用以存储私有组件库。\n搭建私服，可以实现如下功能：\n共享私有依赖，保护敏感信息 保存依赖版本，避免依赖变化或升级受影响 提升代理速读，缓存常用依赖到私服 自定义配置策略、规则、权限等 2.2 为什么选择 Nexus ？ 常见仓库管理有如下几种：\nNexus Repository Manager：Nexus 是一个广泛使用的 Maven 仓库管理器，它提供了丰富的功能，包括支持 Maven、Gradle、Ivy 等构建工具，具有强大的缓存和代理能力，以及用户权限控制、部署规则等功能。\nArtifactory：Artifactory 是另一个流行的 Maven 仓库管理器，它支持多种构建工具，提供了企业级的功能，例如高度可定制的权限控制、智能缓存和复制、跨数据中心复制、虚拟仓库等。\nArchiva：Archiva 是一个轻量级的 Maven 仓库管理器，它提供了基本的 Maven 仓库功能，例如部署、下载和缓存。虽然功能相对较少，但易于安装和使用，适用于小型项目或简单的私有仓库需求。\n选择 Nexus 一来是满足需求，需要的功能都包含，二来是比较熟悉。其他管理系统也都可以，视情况选择即可。\n02 使用 Docker-Compose 搭建 2.1 Docker-Compose 搭建 首先，编写 docker-compose.yaml：\nversion: \u0026#39;3.9\u0026#39; services: nexus: image: sonatype/nexus3:latest #image: sonatype/nexus3:3.56.0 container_name: nexus3 restart: always ports: - 10240:8081 volumes: - ./nexus-data:/nexus-data 然后，创建目录 ./nexus-data 映射数据（不需要备份的就不需要啦），因为需要配置目录权限，所以这里要手动创建目录：\n$ mkdir nexus-data $ chown -R 200 ./nexus-data 这里修改目录所有者，是因为容器创建了 nexus 用户，uid 为 200，如果不修改，启动容器时，会报各种无权限错误：\n# 在容器内查看 bash-4.4$ cat /etc/passwd # …… nexus:x:200:200:Nexus Repository Manager user:/opt/sonatype/nexus:/bin/false 最后启动，等待启动成功即可：\n$ docker-compose up -d 2.2 Nexus 配置 2.2.1 登录系统 上述配置映射了 10240 端口，所以访问 http://ip:10204，使用 admin 登录，nexus3 密码在 nexus-data/admin.password\n$ cat ./nexus-data/admin.password\r9233-22... 2.2.2 配置仓库 首先，顶部选择 【⚙】-\u0026gt; Repository -\u0026gt; Repositories -\u0026gt; ＋ Create Repository\n然后，Recipe 选择 maven2，根据情况选择\nmaven2 (group)：仓库组，也就是「第三方＋私有」仓库 maven2 (hosted)：私服本地，「私有仓库」，私人上传的组件、依赖 maven2 (proxy)：代理，「第三方仓库」，阿里云、华为云等 私服配置 私服（hosted）配置，只需要填写名称即可。\n但是，由于私服存在很多不同阶段的开发依赖版本，所以最好是创建多个仓库，分别存放开发版、稳定版的依赖。\n【Version policy】可以选择 Release 和 Snapshot，当然如果只是简单的测试，直接选择 Mixed 混合模式即可，这样就可以上传任何阶段的依赖了。\n代理配置 代理（proxy）配置，只需要填写名称和地址即可。\n【Remote storage】填写 URL，如 https://maven.aliyun.com/repository/public。\n然后点击【Create repository】即可。\n配置仓库组 仓库组（group）配置，只需要填写名称，然后选择仓库进行组合即可。\n由于开发需要依赖内部 snapshot 版本依赖，所以一般【Version policy】选择 Mixed。\n在 Group -\u0026gt;【Member repositories】中选择需要的仓库，组合起来，保存即可。\n然后，在 Maven 的 settings.xml 只需要配置该仓库组，就可以同时使用多个仓库了。\n2.2.3 配置角色和用户 角色和用户配置相对比较简单，自行测试即可。\n主要是创建角色，分配仓库增删改查权限。然后创建用户，分配角色，就是这么简单的。\nReferences [1] 云中月. docker 中使用 nexus 镜像搭建 maven 私服. 2023-06-06.\n[2] Aqoo. 如何搭建 maven 私有仓库. https://juejin.cn/post/7231902909993631804, 2023-05-11.\n","permalink":"https://blog.springx.fun/posts/tech/docker-compose-install-maven-nexus/","summary":"01 搭建私服的初衷 1.1 为什么搭建私服？ 使用 Maven 管理项目依赖时，通常会从 Maven 仓库拉取第三方依赖，此时只需要配置公共仓库源即可。\n但是，如果需要使用公司内部依赖，需要同时使用第三方依赖和私有依赖，这就需要搭建私服，用以存储私有组件库。\n搭建私服，可以实现如下功能：\n共享私有依赖，保护敏感信息 保存依赖版本，避免依赖变化或升级受影响 提升代理速读，缓存常用依赖到私服 自定义配置策略、规则、权限等 2.2 为什么选择 Nexus ？ 常见仓库管理有如下几种：\nNexus Repository Manager：Nexus 是一个广泛使用的 Maven 仓库管理器，它提供了丰富的功能，包括支持 Maven、Gradle、Ivy 等构建工具，具有强大的缓存和代理能力，以及用户权限控制、部署规则等功能。\nArtifactory：Artifactory 是另一个流行的 Maven 仓库管理器，它支持多种构建工具，提供了企业级的功能，例如高度可定制的权限控制、智能缓存和复制、跨数据中心复制、虚拟仓库等。\nArchiva：Archiva 是一个轻量级的 Maven 仓库管理器，它提供了基本的 Maven 仓库功能，例如部署、下载和缓存。虽然功能相对较少，但易于安装和使用，适用于小型项目或简单的私有仓库需求。\n选择 Nexus 一来是满足需求，需要的功能都包含，二来是比较熟悉。其他管理系统也都可以，视情况选择即可。\n02 使用 Docker-Compose 搭建 2.1 Docker-Compose 搭建 首先，编写 docker-compose.yaml：\nversion: \u0026#39;3.9\u0026#39; services: nexus: image: sonatype/nexus3:latest #image: sonatype/nexus3:3.56.0 container_name: nexus3 restart: always ports: - 10240:8081 volumes: - ./nexus-data:/nexus-data 然后，创建目录 ./nexus-data 映射数据（不需要备份的就不需要啦），因为需要配置目录权限，所以这里要手动创建目录：","title":"使用 Docker-Compose 搭建 Maven 私服 Nexus"},{"content":"碎碎念 对于普通的系统开发，很少会对数据进行细粒度的权限控制。\n但是，在某些需要提供给第三方数据的场景中，要么会直接提供基础数据，要么会提供仅有部分权限的账户。如果是直接提供账户，就需要对账户进行比较精细的权限限制。\n在 mysql 库中，有很多的系统配置表。其中，user 表中存储的是全局的权限，更细粒度的权限分别存储在其他表中。\n01 权限 虽然在上一篇《MySQL 用户管理：创建、权限配置和删除》中提到，修改权限可以直接修改表（update 操作），但是，有些权限涉及其他表，直接修改表不方便，也不建议。\n当然，MySQL 已经为权限提供了 GRANT 和 REVOKE 命令，用于授权和回收权限。\n常见权限名称如下，使用别名授权，就不需要直接 update 数据库了：\n权限别名 权限列名 权限范围 SELECT select_priv Tables or columns INSERT insert_priv Tables or columns UPDATE update_priv Tables or columns DELETE delete_priv Tables CREATE create_priv Databases, tables, or indexes DROP drop_priv Databases, tables, or views INDEX index_priv Tables \u0026hellip; \u0026hellip; \u0026hellip; 具体参考官方文档：6.2.2 Privileges Provided by MySQL\n1.1 全局权限（user） 全局权限存储在 mysql.user 表中，作用于 MySQL 的所有数据库，除了 root，新建用户默认都没有权限（都是 N）\nmysql\u0026gt; select user, host, select_priv, insert_priv, update_priv, delete_priv, create_priv, drop_priv, grant_priv, index_priv from mysql.user where account_locked = \u0026#39;N\u0026#39;; +------+-----------+-------------+-------------+-------------+-------------+-------------+-----------+------------+------------+ | user | host | select_priv | insert_priv | update_priv | delete_priv | create_priv | drop_priv | grant_priv | index_priv | +------+-----------+-------------+-------------+-------------+-------------+-------------+-----------+------------+------------+ | root | localhost | Y | Y | Y | Y | Y | Y | Y | Y | | root | % | Y | Y | Y | Y | Y | Y | Y | Y | +------+-----------+-------------+-------------+-------------+-------------+-------------+-----------+------------+------------+ 增删改查：insert_priv、delete_priv、update_priv、select_priv 创建：create_priv 删除：drop_priv 测试：库的创建和查看\n新创建的用户 springx，没有分配权限，不仅看不到其他库，也没有创建数据库的权限：\nmysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | +--------------------+ mysql\u0026gt; create database test2; ERROR 1044 (42000): Access denied for user \u0026#39;springx\u0026#39;@\u0026#39;%\u0026#39; to database \u0026#39;test2\u0026#39; 错误反馈的原因是 “拒绝访问”，也就是说用户没有 test2 的访问权限，即使 test2 不存在。\n首先，给用户分配库的创建权限：\n*：通配符 格式：库名.表名，*.* 表示所有库表，test.* 表示 test 库中的所有表 -- 授权所有 mysql\u0026gt; GRANT CREATE ON *.* TO springx@\u0026#39;%\u0026#39;; -- 查看权限 mysql\u0026gt; select user, host, select_priv, create_priv from mysql.user where user=\u0026#39;springx\u0026#39;; +---------+------+-------------+-------------+ | user | host | select_priv | create_priv | +---------+------+-------------+-------------+ | springx | % | N | Y | +---------+------+-------------+-------------+ 1）这里如果指定库 test.* 的权限，而不是所有库 *.*，那么就是只有固定库权限（记录在 db 表中） 2）有了创建权限，就能看到库，那么 select_priv 是什么作用呢？ 然后，修改了权限，一般都要 flush privileges 刷新一下，但这里还需要重新登录才能创建库。（创建库完，就能看到了）\n1.2 库级权限（db） 上面分配了 *.* 是全局权限，一般是超管账户才给分配，普通用户只需分配必要库（甚至只分配指定表）的权限。\n库级权限存储在 mysql.db 表中，默认只有两个内置账户：\nmysql\u0026gt; select user, host, select_priv, create_priv from mysql.db; +---------------+-----------+-------------+-------------+ | user | host | select_priv | create_priv | +---------------+-----------+-------------+-------------+ | mysql.session | localhost | Y | N | | mysql.sys | localhost | N | N | +---------------+-----------+-------------+-------------+ 如果指定了库，该用户只能操作指定库下的数据，配置也会记录在 mysql.db 中：\n-- user: root 授权 mysql\u0026gt; GRANT CREATE ON test3.* TO springx@\u0026#39;%\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select user, host, select_priv, create_priv from mysql.db; +---------------+-----------+-------------+-------------+ | user | host | select_priv | create_priv | +---------------+-----------+-------------+-------------+ | springx | % | N | Y | +---------------+-----------+-------------+-------------+ -- user: springx mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | test3 | +--------------------+ 这里授权后，并不需要刷新权限，也不需要重启 CREATE 仅可以对 test3 数据库进行表的创建，没有其他权限 select 失败：ERROR 1142 (42000): SELECT command denied to user 'springx'@'localhost' for table 'user' 1.3 表级权限（tables_priv） 表级顾名思义，就是针对单表进行权限控制，所以分配权限要精确到表，如 test.employee。\n表级权限配置存储在 mysql.tables_priv 表中，默认也只有内置账户。\n当一个用户被赋予了一个库中的其中一个表，那么，该用户就能在 show databases 中查看该库（无需刷新）\n-- 赋予 employee 表的创建权限 mysql\u0026gt; GRANT CREATE ON test.employee TO springx@\u0026#39;%\u0026#39;; Query OK, 0 rows affected (0.00 sec) -- 查看表级权限 mysql\u0026gt; select user, host, table_name, grantor, table_priv from mysql.tables_priv where user=\u0026#39;springx\u0026#39;; +---------+------+------------+----------------+------------+ | user | host | table_name | grantor | table_priv | +---------+------+------------+----------------+------------+ | springx | % | employee | root@localhost | Create | +---------+------+------------+----------------+------------+ 注意，即使表 employee 不存在，也能进行授权。授权后，就可以让该用户自己去创建该表：\n-- user: springx, db: test mysql\u0026gt; show tables; Empty set (0.00 sec) mysql\u0026gt; CREATE TABLE employee ( -\u0026gt; id INT PRIMARY KEY AUTO_INCREMENT, -\u0026gt; name VARCHAR(50) NOT NULL -\u0026gt; ); Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; show tables; +----------------+ | Tables_in_test | +----------------+ | employee | +----------------+ 权限标志，存放在 mysql.tables_priv 中的 table_priv 字段中，多种权限用逗号 , 分割。\n前面只分配了 CREATE 权限，只能创建表，不能做其他操作。这里添加一个 SELECT 测试一下：\nmysql\u0026gt; GRANT SELECT ON test.employee TO springx@\u0026#39;%\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select user, host, table_name, grantor, table_priv from mysql.tables_priv where user=\u0026#39;springx\u0026#39;; +---------+------+------------+----------------+---------------+ | user | host | table_name | grantor | table_priv | +---------+------+------------+----------------+---------------+ | springx | % | employee | root@localhost | Select,Create | +---------+------+------------+----------------+---------------+ 现在，table_priv 字段有了创建和查询的权限，就可以使用 select 查看 employee 表内容了。\n1.4 列级权限（columns_priv） 列级权限，也就是可以对单独列做细粒度控制，配置存储在 mysql.columns_priv 表中。\n回收上一节 test.employee 的所有权限，重新创建表并赋予创建权限：\nmysql\u0026gt; GRANT CREATE ON test.employee TO springx@\u0026#39;%\u0026#39;; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select user, host, db, table_name, grantor, table_priv, column_priv from mysql.tables_priv where db=\u0026#39;test\u0026#39; and user=\u0026#39;springx\u0026#39;; +---------+------+------+------------+----------------+------------+-------------+ | user | host | db | table_name | grantor | table_priv | column_priv | +---------+------+------+------------+----------------+------------+-------------+ | springx | % | test | employee | root@localhost | Create | | +---------+------+------+------------+----------------+------------+-------------+ 此时，springx 用户除了创建 employee 表，没有其他权限。\n测试 1：赋予 springx 对 employee 表的插入权限\n-- 授权 mysql\u0026gt; GRANT INSERT (id, `name`, birth) on test.employee to springx@\u0026#39;%\u0026#39;; Query OK, 0 rows affected (0.00 sec) -- 表级配置 -- 可以看到，tables_priv 中的 column_priv 多了一个 insert 权限 mysql\u0026gt; select user, host, db, table_name, grantor, table_priv, column_priv from mysql.tables_priv where db=\u0026#39;test\u0026#39; and user=\u0026#39;springx\u0026#39;; +---------+------+------+------------+----------------+------------+-------------+ | user | host | db | table_name | grantor | table_priv | column_priv | +---------+------+------+------------+----------------+------------+-------------+ | springx | % | test | employee | root@localhost | Create | Insert | +---------+------+------+------------+----------------+------------+-------------+ -- 列级配置 mysql\u0026gt; select user, host, db, table_name, column_name, column_priv from mysql.columns_priv where db = \u0026#39;test\u0026#39; and user = \u0026#39;springx\u0026#39;; +---------+------+------+------------+-------------+-------------+ | user | host | db | table_name | column_name | column_priv | +---------+------+------+------------+-------------+-------------+ | springx | % | test | employee | id | Insert | | springx | % | test | employee | name | Insert | | springx | % | test | employee | birth | Insert | +---------+------+------+------------+-------------+-------------+ 配置插入权限后，可以正常插入，但还不能查看：\nmysql\u0026gt; insert into employee values(1, \u0026#39;Spring\u0026#39;, \u0026#39;1999-11-11\u0026#39;); Query OK, 1 row affected (0.00 sec) 测试 2：赋予 springx 对 employee 表中 id 和 name 的查看权限\n-- 授权，仅授权两个列 mysql\u0026gt; GRANT SELECT (id, `name`) on test.employee to springx@\u0026#39;%\u0026#39;; Query OK, 0 rows affected (0.01 sec) -- 表级权限 -- 可以看到，tables_priv 中的 column_priv 多了一个 Select 权限 mysql\u0026gt; select user, host, db, table_name, grantor, table_priv, column_priv from mysql.tables_priv where db=\u0026#39;test\u0026#39; and user=\u0026#39;springx\u0026#39;; +---------+------+------+------------+----------------+------------+---------------+ | user | host | db | table_name | grantor | table_priv | column_priv | +---------+------+------+------------+----------------+------------+---------------+ | springx | % | test | employee | root@localhost | Create | Select,Insert | +---------+------+------+------------+----------------+------------+---------------+ -- 列级权限 mysql\u0026gt; select user, host, db, table_name, column_name, column_priv from mysql.columns_priv where db = \u0026#39;test\u0026#39; and user = \u0026#39;springx\u0026#39;; +---------+------+------+------------+-------------+---------------+ | user | host | db | table_name | column_name | column_priv | +---------+------+------+------------+-------------+---------------+ | springx | % | test | employee | id | Select,Insert | | springx | % | test | employee | name | Select,Insert | | springx | % | test | employee | birth | Insert | +---------+------+------+------------+-------------+---------------+ 对两个列授权完成后，id 和 name 都有查看权限，测试一下：\n-- 失败 1：* 失效，没有所有列的查看权限 mysql\u0026gt; select * from employee; ERROR 1142 (42000): SELECT command denied to user \u0026#39;springx\u0026#39;@\u0026#39;localhost\u0026#39; for table \u0026#39;employee\u0026#39; -- 失败 2：对 birth 没有查看权限 mysql\u0026gt; select id, name, birth from employee; ERROR 1143 (42000): SELECT command denied to user \u0026#39;springx\u0026#39;@\u0026#39;localhost\u0026#39; for column \u0026#39;birth\u0026#39; in table \u0026#39;employee\u0026#39; -- 正常 mysql\u0026gt; select id, name from employee; +----+--------+ | id | name | +----+--------+ | 1 | Spring | +----+--------+ 从测试结果可以看出，未对所有列授权时，无法使用通配符（*），也无法使用默认插入（INSERT INTO TB VALUES(...)）等操作，仅能对授权列做指定操作。\n1.5 权限回收（REVOKE） 注意，库表不存在，可以提前授权，同样的，删除库表，并不会回收权限，需要手动回收。所以，不再授权的权限要使用 REVOKE 回收，这也是为什么不推荐直接修改表进行授权的原因（权限越细越麻烦）。\n与授权命令类似，回收命令将 to 换成 from，即“授权给xx”改成“从xx回收权限”。\ne.g.\n-- 授权所有 GRANT CREATE ON *.* TO springx@\u0026#39;%\u0026#39;; -- 回收所有 REVOKE CREATE ON *.* FROM \u0026#39;springx\u0026#39;@\u0026#39;%\u0026#39;; -- 授权表(2 个) GRANT SELECT, INSERT ON test.user to springx@\u0026#39;%\u0026#39;; -- 回收表(1 个) REVOKE SELECT on test3.user from springx@\u0026#39;%\u0026#39;; -- 授权列 GRANT SELECT (birth) on test.employee TO springx@\u0026#39;%\u0026#39;; -- 回收列 REVOKE SELECT (birth) on test.employee FROM springx@\u0026#39;%\u0026#39;; -- …… 02 总结 MySQL 提供了 GRANT 和 REVOKE 命令，用于权限的授予和回收 数据权限从全局、库级、表级到列级，可以进行细粒度控制 授权与回收，跟库表是否存在无关，可以预先授权，也可以删除后再回收权限 如果对列进行部分授权，SELECT * 等默认全部列的操作将无法使用 授权与回收命令比较简单，分别是 GRANT PRIVILEGE.. ON DB.TB TO USER@HOST 和 REVOKE PRIVILEGE.. ON DB.TB FROM USER@HOST References [1] 爱折腾的邦邦. [玩转 MySQL 之三] MySQL 用户及权限. https://zhuanlan.zhihu.com/p/55798418, 2019-01-26.\n","permalink":"https://blog.springx.fun/posts/tech/mysql-data-permission/","summary":"碎碎念 对于普通的系统开发，很少会对数据进行细粒度的权限控制。\n但是，在某些需要提供给第三方数据的场景中，要么会直接提供基础数据，要么会提供仅有部分权限的账户。如果是直接提供账户，就需要对账户进行比较精细的权限限制。\n在 mysql 库中，有很多的系统配置表。其中，user 表中存储的是全局的权限，更细粒度的权限分别存储在其他表中。\n01 权限 虽然在上一篇《MySQL 用户管理：创建、权限配置和删除》中提到，修改权限可以直接修改表（update 操作），但是，有些权限涉及其他表，直接修改表不方便，也不建议。\n当然，MySQL 已经为权限提供了 GRANT 和 REVOKE 命令，用于授权和回收权限。\n常见权限名称如下，使用别名授权，就不需要直接 update 数据库了：\n权限别名 权限列名 权限范围 SELECT select_priv Tables or columns INSERT insert_priv Tables or columns UPDATE update_priv Tables or columns DELETE delete_priv Tables CREATE create_priv Databases, tables, or indexes DROP drop_priv Databases, tables, or views INDEX index_priv Tables \u0026hellip; \u0026hellip; \u0026hellip; 具体参考官方文档：6.2.2 Privileges Provided by MySQL\n1.1 全局权限（user） 全局权限存储在 mysql.user 表中，作用于 MySQL 的所有数据库，除了 root，新建用户默认都没有权限（都是 N）","title":"MySQL 用户数据权限配置"},{"content":"碎碎念 遇到过的很多小伙伴，无论在开发环境，还是在正式环境，都是“一键 ROOT”。包括但不限于 Linux 服务器、MySQL 数据库或者其他中间件，一律使用 ROOT 账户登录使用。\n虽然这么做，可以减少权限等其他不重要的问题，省去很多麻烦，但是，我觉得这个习惯并不好。如果是正式环境，应该尽量避免这种情况。而且，真正需要自己去配置这些的时候，整个过程都会磕磕绊绊。\n作为一个爱折腾的小码农，还是忍不住要弄它几下的。\n01 创建用户 1.1 查询用户 MySQL 所有的用户信息，均保存在数据库名为 mysql 的 user 表中。\nmysql\u0026gt; select user, host, plugin from mysql.user ; +------------------+-----------+-----------------------+ | user | host | plugin | +------------------+-----------+-----------------------+ | root | % | mysql_native_password | | mysql.infoschema | localhost | caching_sha2_password | | mysql.session | localhost | caching_sha2_password | | mysql.sys | localhost | caching_sha2_password | | root | localhost | mysql_native_password | +------------------+-----------+-----------------------+ 从上面的结果可以看到，除了几个内置的账户，默认只有 root 用户。\nhost：表示允许该用户连接到 MySQL 服务器的主机，参考以下示例 %：通配符，允许所有主机连接 192.168.%：允许所有内网 192.168 网段的主机连接 plugin：MySQL 的加密规则 mysql_native_password：MySQL 5 默认 caching_sha2_password：MySQL 8 默认，安全级别更高 1.2 创建用户 1.2.1 MySQL 8 创建用户 创建用户命令格式：CREATE USER 'USER_NAME'@'HOST' IDENTIFIED [WITH plugin] BY 'PASSWORD';\nmysql\u0026gt; CREATE USER \u0026#39;springx\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH caching_sha2_password BY \u0026#39;springx\u0026#39;; Query OK, 0 rows affected (0.01 sec) 创建用户 springx，仅允许从本地登录连接，使用 caching_sha2_password 加密方式，密码为 springx。\nmysql\u0026gt; select user, host, plugin from mysql.user where user = \u0026#39;springx\u0026#39;; +---------+-----------+-----------------------+ | user | host | plugin | +---------+-----------+-----------------------+ | springx | localhost | caching_sha2_password | +---------+-----------+-----------------------+ 测试，能正常登录：\n$ mysql -uspringx -pspringx mysql: [Warning] Using a password on the command line interface can be insecure. ... mysql\u0026gt; 1.2.2 MySQL 5 创建用户 MySQL 5 的用户创建与 8 版本的类似，只不过版本 8 需要先创建用户，然后再进行授权，而版本 5 可以直接创建用户并授权。\nmysql\u0026gt; GRANT ALL PRIVILEGES ON `halo_db`.* TO \u0026#39;springx\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;springx\u0026#39; WITH GRANT OPTION; Query OK, 0 rows affected, 1 warning (0.00 sec) 创建成功，可以正常登录。（warning 应该是数据库 halo_db 不存在，所以提醒的）\n当然，版本 5 也只可以先创建用户，只不过不支持指定加密方式，默认 mysql_native_password：\nmysql\u0026gt; CREATE USER \u0026#39;springx\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;springx2\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select user, host, plugin from mysql.user; +---------------+-----------+-----------------------+ | user | host | plugin | +---------------+-----------+-----------------------+ | springx | % | mysql_native_password | -- 第一次创建（密码 springx） | springx | localhost | mysql_native_password | -- 本次创建 （密码 springx2） +---------------+-----------+-----------------------+ 注意，当存在 host2 包含在 host1 内时，优先使用 host2 规则（即“最小范围原则”——我瞎取的）。\n∃ HOST2 ⊆ HOST1 时，激活 HOST2 规则，否则使用 HOST1 规则\n所以，当从服务器登录时（localhost），只能使用 springx2 密码登录。\n02 权限配置 2.1 登录 IP 限制 添加多个 IP 限制，其实就是「添加多个账户」，只不过他们账户名相同而已，密码可以不同。如果要把两个账户当成一个多 host 账户，密码设置一样即可。\n在上节 1.2 中，创建了用户 springx@localhost，现在添加一个 IP 测试一下：\nmysql\u0026gt; CREATE USER \u0026#39;springx\u0026#39;@\u0026#39;112.86.28.%\u0026#39; IDENTIFIED WITH caching_sha2_password BY \u0026#39;springx2\u0026#39;; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select user, host, plugin from mysql.user ; +------------------+--------------+-----------------------+ | user | host | plugin | +------------------+--------------+-----------------------+ | springx | localhost | caching_sha2_password | -- 密码 springx | springx | 112.86.28.% | caching_sha2_password | -- 密码 springx2 +------------------+--------------+-----------------------+ 注意，虽然用户同名，但是新的用户使用的密码是 springx2 测试一下服务器登录：\n$ mysql -uspringx -pspringx2 mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 1045 (28000): Access denied for user \u0026#39;springx\u0026#39;@\u0026#39;localhost\u0026#39; (using password: YES) 无法从服务器登录，这是预料之中的。原因是密码错误，因为是从服务器（localhost）登录，正确密码应该是第一次添加的用户的密码（即 springx）。\n而从我自己的电脑，使用 springx + springx2，可以正常登录（用 Navicat 就不截图了）。\n注意，由于是创建了新的用户，库表权限需要重新授权。\n另外，也可用通过防火墙进行限制，这不是本文要说的重点，有兴趣的小伙伴可以自行折腾。\n2.2 操作权限限制 数据库的授权，请查看 《MySQL 用户数据权限配置》。\n03 删除用户 3.1 禁用用户 如果只是临时禁用，可以锁定账户，不用完全删除。\n如果要锁定账户，只要修改 mysql.user 的 account_locked 字段，设置为 Y 即可：\nmysql\u0026gt; select user, host, plugin, account_locked from mysql.user where user=\u0026#39;springx\u0026#39;; +---------------+-----------+-----------------------+----------------+ | user | host | plugin | account_locked | +---------------+-----------+-----------------------+----------------+ | springx | % | mysql_native_password | N | | springx | localhost | mysql_native_password | N | +---------------+-----------+-----------------------+----------------+ mysql\u0026gt; update mysql.user set account_locked = \u0026#39;Y\u0026#39; where user=\u0026#39;springx\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 修改权限标志后，记得刷新一下：\nmysql\u0026gt; flush privileges; 对于 mysql.user 表的修改，和修改普通表一样，直接 UPDATE 加条件更新即可。现在，用户已被禁用：\nmysql\u0026gt; select user, host, plugin, account_locked from mysql.user where user=\u0026#39;springx\u0026#39;; +---------+-----------+-----------------------+----------------+ | user | host | plugin | account_locked | +---------+-----------+-----------------------+----------------+ | springx | % | mysql_native_password | Y | | springx | localhost | mysql_native_password | Y | +---------+-----------+-----------------------+----------------+ 上面的 SQL，一次性把用户名为 springx 的所有用户都锁定了，此时登录，会提示“Account is locked”：\n$ mysql -uspringx -pspringx2 mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 3118 (HY000): Access denied for user \u0026#39;springx\u0026#39;@\u0026#39;localhost\u0026#39;. Account is locked. 锁定成功，现在用户 springx 无法登录了\n3.2 删除用户 对于以后不再使用的用户，可以使用 drop 彻底删除：\nmysql\u0026gt; DROP USER \u0026#39;springx\u0026#39;@\u0026#39;localhost\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select user, host, plugin, account_locked from mysql.user where user=\u0026#39;springx\u0026#39;; +---------+------+-----------------------+----------------+ | user | host | plugin | account_locked | +---------+------+-----------------------+----------------+ | springx | % | mysql_native_password | Y | +---------+------+-----------------------+----------------+ DROP 的命令格式：DROP USER 'USER_NAME'[@'HOST']。\n如果不指定 host，那么将删除所有同名账户：\nmysql\u0026gt; DROP USER \u0026#39;springx\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select user, host, plugin, account_locked from mysql.user where user=\u0026#39;springx\u0026#39;; Empty set (0.00 sec) 04 总结 MySQL 8 需要先创建用户，再授权；MySQL 5 可以直接创建用户并授权； 多 IP 登录限制，原理就是创建多个同名账户，账户密码可以不一样，但是库表权限需要重新授权（因为实际是多个不同的用户）； 对于没用的账户，可以修改 mysql.user 表的 account_locked 为 Y 禁用账户，也可以使用 DROP 彻底删除用户 ","permalink":"https://blog.springx.fun/posts/tech/mysql-create-drop-user-and-multi-ip-restriction/","summary":"碎碎念 遇到过的很多小伙伴，无论在开发环境，还是在正式环境，都是“一键 ROOT”。包括但不限于 Linux 服务器、MySQL 数据库或者其他中间件，一律使用 ROOT 账户登录使用。\n虽然这么做，可以减少权限等其他不重要的问题，省去很多麻烦，但是，我觉得这个习惯并不好。如果是正式环境，应该尽量避免这种情况。而且，真正需要自己去配置这些的时候，整个过程都会磕磕绊绊。\n作为一个爱折腾的小码农，还是忍不住要弄它几下的。\n01 创建用户 1.1 查询用户 MySQL 所有的用户信息，均保存在数据库名为 mysql 的 user 表中。\nmysql\u0026gt; select user, host, plugin from mysql.user ; +------------------+-----------+-----------------------+ | user | host | plugin | +------------------+-----------+-----------------------+ | root | % | mysql_native_password | | mysql.infoschema | localhost | caching_sha2_password | | mysql.session | localhost | caching_sha2_password | | mysql.sys | localhost | caching_sha2_password | | root | localhost | mysql_native_password | +------------------+-----------+-----------------------+ 从上面的结果可以看到，除了几个内置的账户，默认只有 root 用户。","title":"MySQL 用户管理：创建、权限配置和删除"},{"content":"01 概述 1.1 环境 CentOS 8\n$ docker --version Docker version 20.10.11, build dea9396 $ docker-compose --version Docker Compose version v2.16.0 1.2 Docker 安装 MySQL 的初始化原理 MySQL Docker 官方介绍：Initializing a refsh instance\nWhen a container is started for the first time, a new database with the specified name will be created and initialized with the provided configuration variables. Furthermore, it will execute files with extensions ++.sh, .sql and .sql.gz++ that are found in /docker-entrypoint-initdb.d. Files will be executed in alphabetical order. You can easily populate your mysql services by mounting a SQL dump into that directory and provide custom images with contributed data. SQL files will be imported by default to the database specified by the MYSQL_DATABASE variable.\n即，容器首次启动后，会做如下初始化动作：\n加载目录为 /docker-entrypoint-initdb.d，后缀为 .sh, sql 和 .sql.gz 的文件 按照文件名的字母顺序，依次执行 默认情况下，SQL 文件将导入到 MYSQL_DATABASE 指定的数据库中（sh 格式暂不了解作用） 02 制作镜像 2.1 编写 Dockerfile 不一定要创建新的镜像，只是在项目部署时，习惯使用自己构建的镜像，定制一点配置，这里只是把初始化 sql 放到镜像中。\n创建一个新的目录，结构如下：\n- db/ # 存放 SQL 文件 - Dockerfile Dockerfile 文件如下：\nFROM mysql:8.0.33 MAINTAINER springx.fun COPY ./db/*.sql /docker-entrypoint-initdb.d/ 2.2 制作镜像 执行 build 制作镜像，自动拉取依赖镜像，并制作自定义镜像：\n$ docker build -t springx.fun/mysql:8.0.33 . Sending build context to Docker daemon 5.12kB Step 1/3 : FROM mysql:8.0.33 8.0.33: Pulling from library/mysql 328ba678bf27: Pulling fs layer f3f5ff008d73: Pulling fs layer dd7054d6d0c7: Downloading 70b5d4e8750e: Waiting ... 参数说明：\n-t：指定构建的镜像名称和标签。例如 -t myapp:latest，构建出来的镜像名称为 myapp，标签为 latest，这里指定 8.0.33 .：Dockerfile 的所在路径或文件名。这里指定当前路径，他会自动找到 Dockerfile 并构建 为什么要手动制作镜像？\n其实如果要使用 Docker Compose，是不用自己手动构建镜像的。但是有遇到过一次异常，Docker Compose 构建的镜像与预期不符，没有可执行的命令，所以紧急情况下手动构建处理（当时是 Docker 19.03.4，可能与 Docker Compose v2.17.2 版本有关？）\n03 使用 Docker Compose 管理容器 3.1 Docker Compose Yaml 配置 编写 docker-compose.yaml 文件：\nversion: \u0026#39;3.9\u0026#39; services: mysql: # 运行起来的容器名称 container_name: mysql-test # 自定构建镜像的镜像名称和标签 image: springx.fun/mysql:8 # 构建镜像的配置 build: # Dockerfile 所在路径 context: ./ # 还可以指定其他参数 # 重启策略：除非用户主动停止，否则出错就一直重启 restart: unless-stopped # 端口映射：宿主端口:容器端口 ports: - 23306:3306 # 环境变量 environment: MYSQL_DATABASE: ${MYSQL_DATABASE:-springx} MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD:-aaa123} TZ: Asia/Shanghai # 映射：把必要数据映射到指定位置 volumes: - ./mysql/logs/:/logs/ - ./mysql/data/:/var/lib/mysql/ - ./mysql/db/:/docker-entrypoint-initdb.d/ - ./mysql/conf.d/:/etc/mysql/conf.d/ # Docker 日志限制，否则会无限大，占据过多磁盘 logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;10m\u0026#34; max-file: \u0026#34;3\u0026#34; 3.2 容器重启策略 Dcoker 容器的重启策略（restart）：\nno：默认，容器退出不重启 on-failure：失败重启，次数可自定义 always：容器退出时，总是重启 unless-stopped：容器退出时重启，除非手动停止 Docker Compose Version 3 配置如下（See restart policy）：\nversion: \u0026#34;3.9\u0026#34; services: mysql: image: mysql:alpine deploy: restart_policy: condition: on-failure # 失败重启 delay: 5s # 尝试间隔 max_attempts: 3 # 最大尝试次数 window: 120s # 在决定重启是否成功之前需要等待多长时间 3.3 MySQL 的环境变量 Docker Compose 支持 ${ENV:-DEFAULT} 格式，从环境变量中获取值，一些通用配置、密码等一般都可以通过这种方式配置。\nENV：环境变量，既可以指定环境文件，也可以记录在默认的 .env 文件中（当前目录下） ENV = XXYY DEFAULT：默认值，如果读取不到 ENV，值使用默认值填充。- 为固定写法。 MYSQL_ROOT_PASSWORD MYSQL_ROOT_PASSWORD 配置 root 用户的初始密码。\n正式环境最好还是修改一下。\nMYSQL_DATABASE MYSQL_DATABASE 配置默认数据库，MySQL 容器启动后，会自动创建该数据库，并且初始化的 sql 默认导入该库中。\n04 启动容器 4.1 Docker 直接启动 使用 Docker 直接运行，需要注意，部分参数需要注意顺序，比如环境变量，需要在指定镜像之前：\n$ docker run \\\r-e \u0026#34;MYSQL_ROOT_PASSWORD=ttt123\u0026#34; \\\r-e \u0026#34;MYSQL_DATABASE=test\u0026#34; \\\rspringx.fun/mysql:8 \\\r--name mysql-test \\\r-d 4.2 Docker Compose 启动 # 启动\r$ docker-compose up -d\r# 查看容器运行情况\r$ docker-compose ps -a\r# 查看日志，看看启动是否有误\r$ docker-compose logs 当 up 命令执行，Docker Compose 会自动执行 build 命令，构建相应的镜像，然后使用该镜像启动一个容器。\n","permalink":"https://blog.springx.fun/posts/tech/mysql-docker-deploy-and-initialization/","summary":"01 概述 1.1 环境 CentOS 8\n$ docker --version Docker version 20.10.11, build dea9396 $ docker-compose --version Docker Compose version v2.16.0 1.2 Docker 安装 MySQL 的初始化原理 MySQL Docker 官方介绍：Initializing a refsh instance\nWhen a container is started for the first time, a new database with the specified name will be created and initialized with the provided configuration variables. Furthermore, it will execute files with extensions ++.sh, .sql and .sql.gz++ that are found in /docker-entrypoint-initdb.","title":"MySQL 的容器化部署与数据库初始化"},{"content":"00 Windows 下的路由 路由是什么？\n路由是指在计算机网络中将数据包从源地址传输到目标地址的过程，通过路由器根据网络拓扑和路由表中的信息进行决策和转发。\nWindows 的路由命令格式如下：\nManipulates network routing tables. 操作网络路由表\n❯ route /? ROUTE [-f] [-p] [-4|-6] command [destination] [MASK netmask] [gateway] [METRIC metric] [IF interface] -f：清除所有路由表项。如果与其中一个命令一起使用，则在运行命令之前清除表。 -p：与 ADD 命令结合使用，标识添加为永久路由 METRIC：跃点数，网络接口顺序，值越小越优先（会自动调整） command：命令，有四个可选命令，分别对应路由的增删改查 PRINT：打印路由 ADD：添加路由 DELETE：删除路由 CHANGE：修改路由 01 查看路由表（print） 查看路由的命令格式如下：\nroute print：查看所有 route print -4：查看 ipv4 路由表 route print -6：查看 ipv6 路由表 route print 192.168.*：查看匹配的路由 示例：查看 172.16.30 相关的路由信息\n❯ route print -4 172.16.30* =========================================================================== Interface List 48...00 15 00 00 00 00 ......Hyper-V Virtual Ethernet Adapter 12...50 eb 00 00 00 00 ......Intel(R) Wireless-AC 9462 1...........................Software Loopback Interface 1 =========================================================================== IPv4 Route Table =========================================================================== Active Routes: # 动态路由表 Network Destination Netmask Gateway Interface Metric 172.16.30.0 255.255.254.0 On-link 172.16.30.76 291 172.16.30.76 255.255.255.255 On-link 172.16.30.76 291 =========================================================================== Persistent Routes: # 永久路由表 None On-link：在链路上，即目标 ip（Network Destination）与接口（Interface）在同一网段 Interface List 中，前面的数字为「接口号码」，接下来是 MAC 地址，后面是接口名称 02 添加路由（add） 添加路由的命令格式如下，如果没有给定 IF，则默认为 gateway 查找一个最合适的接口：\n\u0026gt; route ADD 157.0.0.0 MASK 255.0.0.0 157.55.80.1 METRIC 3 IF 2 destination^ ^mask ^gateway metric^ ^ Interface^ IF interface 的 interface 代表接口号码，可以在 route print 的 Interface List 中查看号码。 2.1 添加默认路由 \u0026gt; route add 0.0.0.0 mask 0.0.0.0 172.16.30.1 OK! 2.2 指定 ip 路由 指定 ip 不可指定 mask，默认 255.255.255.255\n\u0026gt; route add 192.168.199.200 172.16.30.1 IF 10 OK! \u0026gt; route print -4 192.168.199.200 =========================================================================== Active Routes: Network Destination Netmask Gateway Interface Metric 192.168.199.200 255.255.255.0 On-link 172.16.30.1 108 2.3 指定网段路由 添加网段时不能填写具体 ip，网段取值为 0（如 192.168，写成 192.168.0.0）\n\u0026gt; route add 192.168.199.0 mask 255.255.255.0 172.16.30.76 IF 10 OK! \u0026gt; route print -4 192.168.199.* =========================================================================== Active Routes: Network Destination Netmask Gateway Interface Metric 192.168.199.0 255.255.255.0 On-link 172.16.30.76 108 03 删除路由（delete） 删除路由只需指定目标 ip 或网段即可：\n❯ route print -4 192.168.188.* IPv4 Route Table =========================================================================== Active Routes: Network Destination Netmask Gateway Interface Metric 192.168.188.0 255.255.255.0 On-link 172.16.30.76 108 192.168.188.255 255.255.255.255 On-link 172.16.30.76 291 ❯ route delete 192.168.188.255 OK! ❯ route print -4 192.168.188.* IPv4 Route Table =========================================================================== Active Routes: Network Destination Netmask Gateway Interface Metric 192.168.188.0 255.255.255.0 On-link 172.16.30.76 108 04 修改路由（change） 路由修改仅支持更改网关（gateway）和跃点数（metric）\n\u0026gt; route change 192.168.199.200 192.168.199.1 mertic 108 OK! REFERENCES [1] ileeoyo. Windows 路由表“在链路上”. https://ileeoyo.gitee.io/post/windows%E8%B7%AF%E7%94%B1%E8%A1%A8%E5%9C%A8%E9%93%BE%E8%B7%AF%E4%B8%8A/, 2020-05-25.\n","permalink":"https://blog.springx.fun/posts/tech/windows-route/","summary":"00 Windows 下的路由 路由是什么？\n路由是指在计算机网络中将数据包从源地址传输到目标地址的过程，通过路由器根据网络拓扑和路由表中的信息进行决策和转发。\nWindows 的路由命令格式如下：\nManipulates network routing tables. 操作网络路由表\n❯ route /? ROUTE [-f] [-p] [-4|-6] command [destination] [MASK netmask] [gateway] [METRIC metric] [IF interface] -f：清除所有路由表项。如果与其中一个命令一起使用，则在运行命令之前清除表。 -p：与 ADD 命令结合使用，标识添加为永久路由 METRIC：跃点数，网络接口顺序，值越小越优先（会自动调整） command：命令，有四个可选命令，分别对应路由的增删改查 PRINT：打印路由 ADD：添加路由 DELETE：删除路由 CHANGE：修改路由 01 查看路由表（print） 查看路由的命令格式如下：\nroute print：查看所有 route print -4：查看 ipv4 路由表 route print -6：查看 ipv6 路由表 route print 192.168.*：查看匹配的路由 示例：查看 172.16.30 相关的路由信息\n❯ route print -4 172.16.30* =========================================================================== Interface List 48...00 15 00 00 00 00 .","title":"Windows 的路由配置"},{"content":" 在调试本地程序，或者需要把 WSL 的服务暴露出去，使用端口映射会更加方便。\nWindows 的端口映射命令格式如下：\n❯ netsh interface portproxy The following commands are available: Commands in this context: show - Displays information. add - Adds a configuration entry to a table. delete - Deletes a configuration entry from a table. dump - Displays a configuration script. reset - Resets portproxy configuration state. set - Sets configuration information. portproxy：端口代理，它是在强大的网络管理工具 netsh 中，命令本身比较简单，主要就是端口代理的增删改查。\n01 查看映射（show） show 可以查看已存在的端口转发规则，没有给定参数会输出以下帮助信息：\n❯ netsh interface portproxy show The following commands are available: Commands in this context: show all - Shows all port proxy parameters. show v4tov4 - Shows parameters for proxying IPv4 connections to another IPv4 port. show v4tov6 - Shows parameters for proxying IPv4 connections to IPv6. show v6tov4 - Shows parameters for proxying IPv6 connections to IPv4. show v6tov6 - Shows parameters for proxying IPv6 connections to another IPv6 port. show 命令需要指定查看范围，all 表示查看所有，其他的顾名思义表示 ipv4 和 ipv6 之间的转发规则：\n❯ netsh interface portproxy show all Listen on ipv4: Connect to ipv4: Address Port Address Port --------------- ---------- --------------- ---------- * 1024 192.168.198.200 1024 02 添加映射（add） add 用于添加端口转发规则，需要指定 ipv4/ipv6 转发类型：\n❯ netsh interface portproxy add help The following commands are available: Commands in this context: add v4tov4 - Adds an entry to listen on for IPv4 and proxy connect to via IPv4. add v4tov6 - Adds an entry to listen on for IPv4 and proxy connect to via IPv6. add v6tov4 - Adds an entry to listen on for IPv6 and proxy connect to via IPv4. add v6tov6 - Adds an entry to listen on for IPv6 and proxy connect to via IPv6. 具体用法如下：\n❯ netsh interface portproxy add v4tov4 help Usage: add v4tov4 [listenport=]\u0026lt;integer\u0026gt;|\u0026lt;servicename\u0026gt; [connectaddress=]\u0026lt;IPv4 address\u0026gt;|\u0026lt;hostname\u0026gt; [[connectport=]\u0026lt;integer\u0026gt;|\u0026lt;servicename\u0026gt;] [[listenaddress=]\u0026lt;IPv4 address\u0026gt;|\u0026lt;hostname\u0026gt;] [[protocol=]tcp] Parameters: Tag Value listenport - IPv4 port on which to listen.（必须） connectaddress - IPv4 address to which to connect.（必须） connectport - IPv4 port to which to connect.（必须） listenaddress - IPv4 address on which to listen.（可选，默认所有 *） protocol - Protocol to use. Currently only TCP is supported.（目前仅支持 TCP，不用填） 示例：把端口 1025 的流量转发到 wsl 的 1025 端口上，让外部机器能直接访问到 wsl 子系统（默认到 0.0.0.0）\n❯ netsh interface portproxy add v4tov4 listenport=1025 connectaddress=192.168.198.200 connectport=1025 ❯ netsh interface portproxy show all Listen on ipv4: Connect to ipv4: Address Port Address Port --------------- ---------- --------------- ---------- * 1024 192.168.198.200 1024 * 1025 192.168.198.200 1025 前提：防火墙需要开启 1024 入口规则 1）本地监听 1025 端口 2）把 1025 端口连接到 192.168.198.200 的 1025 端口，这样，请求本机 1025 的流量，都会转到 wsl 的 1025 03 删除映射（delete） delete 同样要指定 ip 类型，删除时只需指定监听的地址和端口即可：\nlistenaddress：监听地址，可选（默认 *） listenport: 监听端口，必选 ❯ netsh interface portproxy delete v4tov4 listenport=1025 ❯ netsh interface portproxy show all Listen on ipv4: Connect to ipv4: Address Port Address Port --------------- ---------- --------------- ---------- * 1024 192.168.198.200 1024 04 输出配置（备份，dump） dump 命令输出已配置的转发规则，用于备份已存在的规则，可以重定向到文件保存起来。\n❯ netsh interface portproxy show all Listen on ipv4: Connect to ipv4: Address Port Address Port --------------- ---------- --------------- ---------- 0.0.0.0 1024 192.168.198.200 1024 ❯ netsh interface portproxy dump #======================== # Port Proxy configuration #======================== pushd interface portproxy reset add v4tov4 listenport=1024 connectaddress=192.168.198.200 connectport=1024 popd # End of Port Proxy configuration 示例：备份到文件（没有找到还原方式，官方文档没有 dump 参数，有点尬。。。）\n# 备份 \u0026gt; netsh interface portproxy dump \u0026gt; portproxy.bak 05 修改或添加（set） set 命令可以修改或新增转发规则。\n新增规则：\n❯ netsh interface portproxy set v4tov4 listenaddress=0.0.0.0 listenport=1024 connectaddress=192.168.198.200 connectport=2048 ❯ netsh interface portproxy show all Listen on ipv4: Connect to ipv4: Address Port Address Port --------------- ---------- --------------- ---------- * 1024 192.168.198.200 1024 0.0.0.0 1024 192.168.198.200 2048 修改规则：\n❯ netsh interface portproxy set v4tov4 listenaddress=0.0.0.0 listenport=1024 connectaddress=192.168.198.200 connectport=2049 ❯ netsh interface portproxy show all Listen on ipv4: Connect to ipv4: Address Port Address Port --------------- ---------- --------------- ---------- * 1024 192.168.198.200 1024 0.0.0.0 1024 192.168.198.200 2049 06 重置映射（清空，reset） 清空所有规则，慎用：\n# 重置 ❯ netsh interface portproxy reset # 查看 ❯ netsh interface portproxy show all ","permalink":"https://blog.springx.fun/posts/tech/windows-port-proxy/","summary":"在调试本地程序，或者需要把 WSL 的服务暴露出去，使用端口映射会更加方便。\nWindows 的端口映射命令格式如下：\n❯ netsh interface portproxy The following commands are available: Commands in this context: show - Displays information. add - Adds a configuration entry to a table. delete - Deletes a configuration entry from a table. dump - Displays a configuration script. reset - Resets portproxy configuration state. set - Sets configuration information. portproxy：端口代理，它是在强大的网络管理工具 netsh 中，命令本身比较简单，主要就是端口代理的增删改查。\n01 查看映射（show） show 可以查看已存在的端口转发规则，没有给定参数会输出以下帮助信息：\n❯ netsh interface portproxy show The following commands are available: Commands in this context: show all - Shows all port proxy parameters.","title":"Windows 的端口代理配置（端口映射）"},{"content":"GBK 和 Unicode 之间的转换问题 1. GBK 被解密为 UTF-8 正常的 GBK 字节流，以为是 UTF-8，所以用 UTF-8 去解码：\n输出特点：一堆的黑色菱形+问号 输出示例：�Ҳ����� @Test public void test() throws UnsupportedEncodingException { String str = \u0026#34;我不是锟斤拷\u0026#34;; byte[] buff = str.getBytes(\u0026#34;GBK\u0026#34;); // 这里只要不抛异常，数据一定不会被破坏 String str1 = new String(buff, \u0026#34;UTF-8\u0026#34;); } 2. UTF-8 被解密为 GBK 正常的 UTF-8 字节流，以为是 GBK，所以用 GBK 去解码：\n输出示例：鎴戜笉鏄敓鏂ゆ嫹 @Test public void test() throws UnsupportedEncodingException { String str = \u0026#34;我不是锟斤拷\u0026#34;; byte[] buff = str.getBytes(\u0026#34;UTF-8\u0026#34;); // 这里只要不抛异常，数据一定不会被破坏 String str1 = new String(buff, \u0026#34;GBK\u0026#34;); // 这里破坏了 } 3. \u0026ldquo;锟斤拷\u0026quot;的由来 正常的 GBK 字节流，中途被 UTF-8 解码了，又用 GBK 解码一遍：\n输出特点：锟斤拷锟斤拷 输出示例：锟揭诧拷锟斤拷锟斤拷 @Test public void test() throws UnsupportedEncodingException { String str = \u0026#34;我不是锟斤拷\u0026#34;; byte[] gbk = str.getBytes(\u0026#34;GBK\u0026#34;); // 原来的 GBK str = new String(gbk, \u0026#34;UTF-8\u0026#34;); // 中途被转为 UTF-8 String str1 = new String(str.getBytes(StandardCharsets.UTF_8), \u0026#34;GBK\u0026#34;); } 总结分析 情况 1、2 是使用错误编码方式 情况 3 是中途被改变的（如 HTTP 请求回来，默认用 UTF8 生成字符串，此时就被转码了） Reference [1] pollyduan. 一段 java 代码带你认识锟斤拷[EB/OL]. https://cloud.tencent.com/developer/article/1532357, 2019-11-04.\n","permalink":"https://blog.springx.fun/posts/tech/java-the-conversion-between-gbk-and-unicode/","summary":"GBK 和 Unicode 之间的转换问题 1. GBK 被解密为 UTF-8 正常的 GBK 字节流，以为是 UTF-8，所以用 UTF-8 去解码：\n输出特点：一堆的黑色菱形+问号 输出示例：�Ҳ����� @Test public void test() throws UnsupportedEncodingException { String str = \u0026#34;我不是锟斤拷\u0026#34;; byte[] buff = str.getBytes(\u0026#34;GBK\u0026#34;); // 这里只要不抛异常，数据一定不会被破坏 String str1 = new String(buff, \u0026#34;UTF-8\u0026#34;); } 2. UTF-8 被解密为 GBK 正常的 UTF-8 字节流，以为是 GBK，所以用 GBK 去解码：\n输出示例：鎴戜笉鏄敓鏂ゆ嫹 @Test public void test() throws UnsupportedEncodingException { String str = \u0026#34;我不是锟斤拷\u0026#34;; byte[] buff = str.getBytes(\u0026#34;UTF-8\u0026#34;); // 这里只要不抛异常，数据一定不会被破坏 String str1 = new String(buff, \u0026#34;GBK\u0026#34;); // 这里破坏了 } 3.","title":"GBK 和 Unicode 之间的转换问题——“锟斤拷”的由来"},{"content":"从第一个缓存框架 Memcached 诞生以来，缓存就广泛地存在于互联网应用中。如果你的应用流量很小，那么使用缓存可能并不需要做多余的考虑。但如果你的应用流量达到了成百上千万，那么你就不得不考虑深层次的缓存问题：缓存穿透、缓存击穿与缓存雪崩。\n缓存穿透 缓存穿透是指查询一个一定不存在的数据，因为这个数据不存在，所以永远不会被缓存，所以每次请求都会去请求数据库。\n例如我们请求一个 UserID 为 -1 的用户数据，因为该用户不存在，所以该请求每次都会去读取数据库。在这种情况下，如果某些心怀不轨的人利用这个存在的漏洞去伪造大量的请求，那么很可能导致DB承受不了那么大的流量就挂掉了。\n对于缓存穿透，有几种解决方案，一种是事前预防，一种是事后预防。\n事前预防 事前预防其实就是对所有请求都进行参数校验，把绝大多数非法的请求抵挡在最外层。在我们举的这个例子中，那么就是做参数校验，对于 UserID 小于 0 的请求全部拒绝。但即使我们做了全面的参数校验，还是可能存在漏网之鱼，会出现一些我们没想到的情况。\n例如我们的 UserID 是递增的，那么如果有人请求一个 UserID 很大的用户信息（例如：1000000），而我们的 UserID 最大也就 10000。这个时候，你不可能限制 UserID 大于 1 万的就是非法的，或者说大于 10 万就是非法的，所以该用户ID肯定可以通过参数校验。但该用户确实不存在，所以每次请求都会去请求数据库。\n其实上面只是我所能想到的一种情况，我们没想到的情况肯定还有很多。对于这些情况，我们能做的就是事后预防。\n事后预防 事后预防说的就是当查询到一个空的结果时，我们仍然将这个空的结果进行缓存，但是设置一个很短的过期时间（例如一分钟），但是这种办法还是没办法预防非常多的非法值。\n另外一个比较有效的办法是，将这个字段里在数据库中的所有值存在布隆过滤器中。当一个查询请求过来时，先经过布隆过滤器进行查，如果判断请求查询值存在，则继续查数据库。如果判断请求查询不存在，直接丢弃。\n通过上面这两种处理方式，我们基本可以解决缓存穿透的问题。事前预防解决 80% 的非法请求，剩下的 20% 非法请求则使用 Redis 转移风险。\n缓存击穿 如果你的应用中有一些访问量很高的热点数据，我们一般会将其放在缓存中以提高访问速度。另外，为了保持时效性，我们通常还会设置一个过期时间。但是对于这些访问量很高的KEY，我们需要考虑一个问题：当热点KEY在失效的瞬间，海量的请求会不会产生大量的数据库请求，从而导致数据库崩溃？\n例如我们有一个业务 KEY，该 KEY 的并发请求量为 10000。当该 KEY 失效的时候，就会有 1 万个线程会去请求数据库更新缓存。这个时候如果没有采取适当的措施，那么数据库很可能崩溃。\n其实上面这个问题就是缓存击穿的问题，它发生在缓存 KEY 的过期瞬间。对于这种情况，现在常用的解决方式有这么两种：互斥锁、永远不过期。\n互斥锁 互斥锁指的是在缓存 KEY 过期去更新的时候，先让程序去获取锁，只有获取到锁的线程才有资格去更新缓存 KEY。其他没有获取到锁的线程则休眠片刻之后再次去获取最新的缓存数据。通过这种方式，同一时刻永远只有一个线程会去读取数据库，这样也就避免了海量数据库请求对于数据库的冲击。\n而对于上面说到的锁，我们可以使用缓存提供的一些原则操作来完成。例如对于 redis 缓存来说，我们可以使用其 SETNX 命令来完成。\npublic String get(key) { String value = redis.get(key); if (value == null) { //缓存过期 if (redis.setnx(key_mutex, 1, 1 * 60) == 1) { value = db.get(key); redis.set(key, value, expireTime); redis.del(key_mutex); } else { //休眠片刻后重试 sleep(50); get(key); } } else { return value; } } 上面的 key_mutex 其实就是一个普通的 KEY-VALUE 值，我们使用 setnx 命令去设置其值为 1。如果这时候已经有人在更新缓存 KEY 了，那么 setnx 命令会返回 0，表示设置失败。\n永远不过期 从缓存的角度来看，如果你设置了永远不过期，那么就不会有海量请求数据库的情形出现。此时我们一般通过新起一个线程的方式去定时将数据库中的数据更新到缓存中，更加成熟的方式是通过定时任务去同步缓存和数据库的数据。\n但这种方案会出现数据的延迟问题，也就是线程读取到的数据并不是最新的数据。但对于一般的互联网功能来说，些许的延迟还是能接受的。\n缓存雪崩 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到数据库，最终导致数据库瞬时压力过大而崩溃。\n例如我们有 1000 个 KEY，而每个 KEY 的并发请求不大，只有 10 次。而缓存雪崩指的就是这 1000 个 KEY 在同一时间，同时失效，这个时候就突然有 1000 ** 10 = 一万次查询。\n缓存雪崩导致的问题一般很难排查，如果没有事先预防，很可能要花很大力气才能找得到原因。对于缓存雪崩的情况，最简单的方案就是在原有失效时间的基础上增加一个随机时间（例如1-5分钟），这样每个缓存过期时间的重复率就会降低，从而减少缓存雪崩的发生。\n总结 对于缓存穿透、缓存击穿、缓存雪崩这三个情景，许多人会搞不明白，甚至会混淆。\n「缓存穿透」 指的是请求不存在的数据，从而使得缓存形同虚设，缓存层被穿透了。例如我们请求一个 UserID 为 -1 的用户数据，因为该用户不存在，所以该请求每次都会去读取数据库。在这种情况下，如果某些心怀不轨的人利用这个存在的漏洞去伪造大量的请求，那么很可能导致 DB 承受不了那么大的流量就挂掉了。\n「缓存击穿」 指的是并发量很高的 KEY，在该 KEY 失效的瞬间有很多请求同同时去请求数据库，更新缓存。例如我们有一个业务 KEY，该 KEY 的并发请求量为 10000。当该 KEY 失效的时候，就会有 1 万个线程会去请求数据库更新缓存。这个时候如果没有采取适当的措施，那么数据库很可能崩溃。\n「缓存雪崩」 则是指大量缓存在同一时间同时过期，就像所有雪块同一时刻掉下来，像雪崩一样。例如我们有 1000 个KEY，而每个 KEY 的并发请求不大，只有 10 次。而缓存雪崩指的就是这 1000 个 KEY 在同一时间，同时失效，这个时候就突然有 1000 ** 10 = 一万次查询。\n对于它们出现的情形，我们可以做一些总结：\n「缓存穿透」 是业务层面的漏洞导致非法请求，与请求量、缓存失效没关系。「缓存击穿」 则只会出现在热点数据上，发生在缓存失效的瞬间，与业务没多大关系。「缓存雪崩」 则是因为多个 KEY 同时失效，导致数据库请求太多。非热点数据也会导致缓存雪崩，只要同时失效的 KEY 足够多。\n[原文地址]\n面对海量请求，缓存设计还应该考虑哪些问题？ - 陈树义的博客 (shuyi.tech)\n","permalink":"https://blog.springx.fun/posts/tech/redis-penetration-breakdown-avalanche/","summary":"从第一个缓存框架 Memcached 诞生以来，缓存就广泛地存在于互联网应用中。如果你的应用流量很小，那么使用缓存可能并不需要做多余的考虑。但如果你的应用流量达到了成百上千万，那么你就不得不考虑深层次的缓存问题：缓存穿透、缓存击穿与缓存雪崩。\n缓存穿透 缓存穿透是指查询一个一定不存在的数据，因为这个数据不存在，所以永远不会被缓存，所以每次请求都会去请求数据库。\n例如我们请求一个 UserID 为 -1 的用户数据，因为该用户不存在，所以该请求每次都会去读取数据库。在这种情况下，如果某些心怀不轨的人利用这个存在的漏洞去伪造大量的请求，那么很可能导致DB承受不了那么大的流量就挂掉了。\n对于缓存穿透，有几种解决方案，一种是事前预防，一种是事后预防。\n事前预防 事前预防其实就是对所有请求都进行参数校验，把绝大多数非法的请求抵挡在最外层。在我们举的这个例子中，那么就是做参数校验，对于 UserID 小于 0 的请求全部拒绝。但即使我们做了全面的参数校验，还是可能存在漏网之鱼，会出现一些我们没想到的情况。\n例如我们的 UserID 是递增的，那么如果有人请求一个 UserID 很大的用户信息（例如：1000000），而我们的 UserID 最大也就 10000。这个时候，你不可能限制 UserID 大于 1 万的就是非法的，或者说大于 10 万就是非法的，所以该用户ID肯定可以通过参数校验。但该用户确实不存在，所以每次请求都会去请求数据库。\n其实上面只是我所能想到的一种情况，我们没想到的情况肯定还有很多。对于这些情况，我们能做的就是事后预防。\n事后预防 事后预防说的就是当查询到一个空的结果时，我们仍然将这个空的结果进行缓存，但是设置一个很短的过期时间（例如一分钟），但是这种办法还是没办法预防非常多的非法值。\n另外一个比较有效的办法是，将这个字段里在数据库中的所有值存在布隆过滤器中。当一个查询请求过来时，先经过布隆过滤器进行查，如果判断请求查询值存在，则继续查数据库。如果判断请求查询不存在，直接丢弃。\n通过上面这两种处理方式，我们基本可以解决缓存穿透的问题。事前预防解决 80% 的非法请求，剩下的 20% 非法请求则使用 Redis 转移风险。\n缓存击穿 如果你的应用中有一些访问量很高的热点数据，我们一般会将其放在缓存中以提高访问速度。另外，为了保持时效性，我们通常还会设置一个过期时间。但是对于这些访问量很高的KEY，我们需要考虑一个问题：当热点KEY在失效的瞬间，海量的请求会不会产生大量的数据库请求，从而导致数据库崩溃？\n例如我们有一个业务 KEY，该 KEY 的并发请求量为 10000。当该 KEY 失效的时候，就会有 1 万个线程会去请求数据库更新缓存。这个时候如果没有采取适当的措施，那么数据库很可能崩溃。\n其实上面这个问题就是缓存击穿的问题，它发生在缓存 KEY 的过期瞬间。对于这种情况，现在常用的解决方式有这么两种：互斥锁、永远不过期。\n互斥锁 互斥锁指的是在缓存 KEY 过期去更新的时候，先让程序去获取锁，只有获取到锁的线程才有资格去更新缓存 KEY。其他没有获取到锁的线程则休眠片刻之后再次去获取最新的缓存数据。通过这种方式，同一时刻永远只有一个线程会去读取数据库，这样也就避免了海量数据库请求对于数据库的冲击。\n而对于上面说到的锁，我们可以使用缓存提供的一些原则操作来完成。例如对于 redis 缓存来说，我们可以使用其 SETNX 命令来完成。\npublic String get(key) { String value = redis.","title":"Redis 的缓存穿透、缓存击穿和缓存雪崩问题"},{"content":"01 curl 和 wget 的区别 wget 是个专职的下载利器，简单，专一，极致；\ncurl 可以下载，但是长项不在于下载，而在于模拟提交 web 数据，POST/GET 请求，调试网页，等等。\n02 具体使用（下载） 下载文件 curl -O http://man.linuxde.net/text.iso # O大写，不用O只是打印内容不会下载 wget http://www.linuxde.net/text.iso # 不用参数，直接下载文件 下载文件并重命名 curl -o rename.iso http://man.linuxde.net/text.iso # o小写 wget -O rename.zip http://www.linuxde.net/text.iso # O大写 断点续传 curl -O -C - http://man.linuxde.net/text.iso # O大写；C大写，- 表示不指定续传的偏移量，默认从本地文件计算 wget -c http://www.linuxde.net/text.iso # c小写 限速下载 curl --limit-rate 50k -O http://man.linuxde.net/text.iso wget --limit-rate=50k http://www.linuxde.net/text.iso 显示响应头部信息 curl -I http://man.linuxde.net/text.iso wget --server-response http://www.linuxde.net/test.iso wget 利器 → 打包下载网站 wget --mirror -p --convert-links -P /var/www/html http://man.linuxde.net/ References [1] https://www.zhihu.com/question/19598302\n[2] https://www.cnblogs.com/lsdb/p/7171779.html\n","permalink":"https://blog.springx.fun/posts/tech/linux-curl-vs-wget/","summary":"01 curl 和 wget 的区别 wget 是个专职的下载利器，简单，专一，极致；\ncurl 可以下载，但是长项不在于下载，而在于模拟提交 web 数据，POST/GET 请求，调试网页，等等。\n02 具体使用（下载） 下载文件 curl -O http://man.linuxde.net/text.iso # O大写，不用O只是打印内容不会下载 wget http://www.linuxde.net/text.iso # 不用参数，直接下载文件 下载文件并重命名 curl -o rename.iso http://man.linuxde.net/text.iso # o小写 wget -O rename.zip http://www.linuxde.net/text.iso # O大写 断点续传 curl -O -C - http://man.linuxde.net/text.iso # O大写；C大写，- 表示不指定续传的偏移量，默认从本地文件计算 wget -c http://www.linuxde.net/text.iso # c小写 限速下载 curl --limit-rate 50k -O http://man.linuxde.net/text.iso wget --limit-rate=50k http://www.linuxde.net/text.iso 显示响应头部信息 curl -I http://man.linuxde.net/text.iso wget --server-response http://www.linuxde.net/test.iso wget 利器 → 打包下载网站 wget --mirror -p --convert-links -P /var/www/html http://man.","title":"curl 于 wget 的区别（下载文件）"},{"content":"在使用 MySQL 时，有时需要查询出某个字段不重复的记录，这时可以使用 MySQL 提供的 distinct 这个关键字来过滤重复的记录[1]。\n语法格式：\nselect distinct expression[,expression...] from tables [where conditions]; 01 distinct 的用法 例如，我们有表如下：\nmysql\u0026gt; select * from user; +----+----------+----------+ | id | username | password | +----+----------+----------+ | 1 | taylor | pass123 | | 2 | spring | pass456 | | 3 | Yahto | taf23 | | 4 | Lillie | flowwer | | 5 | Lia | wherend | | 6 | Lia2 | wherend | | 7 | Lia3 | wherend | | 8 | Lia4 | wherend | +----+----------+----------+ 1.1 简单的用法 用 distinct 返回不重复的密码：\nmysql\u0026gt; select distinct password from user; +----------+ | password | +----------+ | pass123 | | pass456 | | taf23 | | flowwer | | wherend | -- 去除了其他 3 个重复字段 +----------+ 但是，这样只能查出不同的密码，不能查出密码对应的用户 id 或用户名。\n实际开发中，我们往往用 distinct 来返回不重复字段的条数（count(distinct id)），就是因为 distinct 只能返回它的目标字段，而无法返回其他字段。\n1.2 distinct 的注意事项 从最前面 distinct 的语法格式可以看出[2]：\ndistinct 要放在所有字段的前面 如果去重的字段大于一个，则会进行组合去重，只有多个字段组合起来相同时才会被去重 mysql\u0026gt; select distinct username, password from user; +----------+----------+ | username | password | +----------+----------+ | taylor | pass123 | | spring | pass456 | | Yahto | taf23 | | Lillie | flowwer | | Lia | wherend | -- 由于 username 不同，故 password 相同也不能去重 | Lia2 | wherend | | Lia3 | wherend | | Lia4 | wherend | +----------+----------+ 02 可能遇到的其他用法 2.1 错误使用 distinct(c) 不知道你们有没有遇到过这样的例子：\n要求查出所有用户，并根据手机号过滤重复记录。。。\n可能一不小心就会遇到这样子的查询语句（这里用过滤相同密码来试验）：\nmysql\u0026gt; select distinct(password), username from user; +----------+----------+ | password | username | +----------+----------+ | pass123 | taylor | | pass456 | spring | | taf23 | Yahto | | flowwer | Lillie | | wherend | Lia | -- 其实还是过滤 password+username | wherend | Lia2 | | wherend | Lia3 | | wherend | Lia4 | +----------+----------+ distinct(column_name) 并没有按照函数操作那样，仅对括号内的列进行去重，而是依旧对 distinct 后面的所有列进行组合去重。（其实这里 distinct 也只能放在最前面，放到后面就会报错了）\n2.2 计数 count(distinct c) 计数方式的两种情况。\n第一种，计算指定字段的出现次数，可以直接用 count：\nmysql\u0026gt; select count(username) AS total -\u0026gt; from user -\u0026gt; where password = \u0026#39;wherend\u0026#39;; +-------+ | total | +-------+ | 4 | +-------+ 第二种，计算所有字段的出现次数，先根据 password 分组，然后计数时根据不同的 username 来计算（如果用户名一样，则认为是相同的）\nmysql\u0026gt; select -\u0026gt; password, count(distinct username) as num -\u0026gt; from -\u0026gt; user -\u0026gt; group by -\u0026gt; password; +----------+-----+ | password | num | +----------+-----+ | flowwer | 1 | | pass123 | 1 | | pass456 | 1 | | taf23 | 1 | | wherend | 4 | +----------+-----+ 总结 因为 distinct 只能返回他的目标字段，而无法返回其他字段，故一般用来计算不重复字段的条数（须先分组） mysql\u0026gt; select -\u0026gt; password, count(distinct id) AS num -\u0026gt; from -\u0026gt; user -\u0026gt; group by password; +----------+-----+ | password | num | +----------+-----+ | flowwer | 4 | | pass123 | 1 | +----------+-----+ 单纯去除重复，以便获取去重后的集合 mysql\u0026gt; select distinct password from user; +----------+ | password | +----------+ | pass123 | | pass456 | +----------+ 完。\nREFERENCES [1] 失落的黎明. mysql 中去重 distinct 用法: https://www.cnblogs.com/shiluoliming/p/6604407.html\n[2] 有梦想的攻城狮. mysql 中的 distinct 的用法: https://blog.csdn.net/zhangzehai2234/article/details/88361586\n","permalink":"https://blog.springx.fun/posts/tech/mysql-distinct/","summary":"在使用 MySQL 时，有时需要查询出某个字段不重复的记录，这时可以使用 MySQL 提供的 distinct 这个关键字来过滤重复的记录[1]。\n语法格式：\nselect distinct expression[,expression...] from tables [where conditions]; 01 distinct 的用法 例如，我们有表如下：\nmysql\u0026gt; select * from user; +----+----------+----------+ | id | username | password | +----+----------+----------+ | 1 | taylor | pass123 | | 2 | spring | pass456 | | 3 | Yahto | taf23 | | 4 | Lillie | flowwer | | 5 | Lia | wherend | | 6 | Lia2 | wherend | | 7 | Lia3 | wherend | | 8 | Lia4 | wherend | +----+----------+----------+ 1.","title":"MySQL 去重之 distinct"},{"content":"00 Go 环境配置 首先，下载 Golang 安装包，地址：https://go.dev/dl/。\n接着，将 Golang 安装包解压到指定路径。\n然后，把 Go 安装路径配置到环境变量。有如下两个环境变量：\nGOROOT：可选，主要是将 $GOROOT/bin 配置到环境变量中以便直接使用 go 命令及其工具等 GOPATH：Go 1.11 之后引入 Go Modules，不再完全依赖 GOPATH 了 Go 1.11 之前，go get 下载的包会被存放在 $GOPATH/src 目录下，与项目无关 Go 1.11 之后（使用了 Go Modules），依赖包会被存放在项目的 go.mod 指定的缓存目录中，默认情况下是 $GOPATH/pkg/mod 01 Go 基础 1.1 变量 类型：放在变量名后面 变量声明：var NAME TYPE 简单变量声明：NAME := VALUE（只允许在函数内部使用，且不能用于声明静态变量） 数据类型 bool string // 不出初始化，则默认空字符串：\u0026#34;\u0026#34; int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr byte // alias for uint8 rune // alias for int32 // represents a Unicode code point float32 float64 complex64 complex128 // 复数 var x complex128 = complex(1, 2) // 1+2i var y complex128 = complex(3, 4) // 3+4i fmt.Println(x*y) // \u0026#34;(-5+10i)\u0026#34; fmt.Println(real(x*y)) // \u0026#34;-5\u0026#34; fmt.Println(imag(x*y)) // \u0026#34;10\u0026#34; 1.2 循环 Go 只有 for 循环，且格式固定：\n// 没有小括号，大括号必须有 for i := 0; i \u0026lt; 10; i++ { // do ... } // Go 的 while 是 for 的特例 for s \u0026lt; 1000 { // do ... } // 忽略其他条件，死循环，即 while(true) for { // do ... } 1.3 条件判断 Go 的条件判断有 if 和 switch。if 的区别是：\n可以省略小括号 可以有初始语句，类似 for 循环的初始化变量语句 // 可以省略小括号，大括号必须有 if x \u0026lt; 0 { // do } // 还可以有多语句 if v := f(x, n); v \u0026lt; n { // do } Switch 的区别比较大，它只执行单个 case，然后自动 break\n默认 break，如果需要继续执行，则须使用 fallthrough 条件可以为空：相当于 switch true，可以代替很长的 if else switch os := runtime.GOOS; os { case \u0026#34;darwin\u0026#34;: // do case \u0026#34;linux\u0026#34;: // do fallthrough default: // do } // if else switch { case x \u0026lt; 0: // if x \u0026lt; 0 case x \u0026lt; 2: // if x \u0026lt; 2 default: // else } 1.4 延迟调用（defer） Go 比 C/Java 多了延迟调用函数 defer。延迟调用的函数的参数会立即计算，但函数在当前函数 return 时（结束）才执行。\ndefer 函数入栈，故多个延迟函数将倒序执行。 另一个作用：配合 recover() 捕获异常。 // x = 1, y = 1 func test(x, y int) int { defer my_defer(\u0026amp;x, y+1) // *param1 = 1, param2 = 2 fmt.Println(\u0026#34;test: x = \u0026#34;, x) // x = 1，x 的值如果修改，defer 的 x 将同步修改！ return x } 1.5 指针与结构体 Go 有指针，但没有指针运算（C 中的 int *p = \u0026amp;arr; p++; ...）\nvar p *int i := 222 p = \u0026amp;i *p = 22 Go 和 C 一样都有结构体，但它可以指定变量初始化，初始化方式稍微有些差异：\ntype Vertex struct { x, y int } var ( v1 = Vertex{1, 2} v2 = Vertex{y: 3} p = \u0026amp;Vertex{1,1} // p.x == 1, p.y == 1 ) 1.6 切片（Slice） Go 的切片 Slices 和 JavaScript 的 Array 有相似之处\n切片不存储数据，仅指向数组的位置，数组改变切片也会改变。 切片有长度和容量：len(s) and cap(s)（注意左边的取值会影响容量） // 左闭右开区间 primes := [6]int{2, 3, 4, 5, 6} // s = {3, 4, 5} var s []int = primes[1:4] // 可省略左右区间值：左-0，右-length var s = primes[:2] // 2,3 var s = primes[2:] // 4,5,6 var s = primes[:] // 同原数组 fmt.Printf(\u0026#34;len=%d cap=%d %v\\n\u0026#34;, len(s), cap(s), s) // 可以看作创建了一个空的数组，s 是指向这个数组的切片，则 s == nil var s []int // 遍历 for INDEX, ELEMENT := range SLICE { // DO... } 动态创建切片，使用 make 预分配空间。在实际使用的过程中，如果容量不够，切片容量会自动扩展\nvar s = make([]int, 5) // len=5 cap=5 [0,0,0,0,0] var s = make([]int, 0, 5) // len=0 cap=5 [] 添加到切片，使用 append 添加/合并，切记不要合并不同的两个切片\n// func append(s []T, vs ...T) []T var s = append(s, 1, 2) // [[s], 1, 2] // Do not do this!!! // 1. 容量不够，会创建新切片 someSlice = append(otherSlice, element) // 2. 容量够，会直接加入，多次创建新的会覆盖旧的 a := make([]int, 3, 8) b := append(a, 5) // b = [0, 0, 0, 5] c := append(a, 6) // b = [0, 0, 0, 6] // c = [0, 0, 0, 5] 1.7 可变参数与展开操作符 Go 没有明确的 Spread Operator 操作符，而 ... 可以将切片展开为可变参数列表\npackage main import \u0026#34;fmt\u0026#34; func variadicParam(nums ...int) int { // nums is a slice total := 0 for i := 0; i \u0026lt; len(nums); i++ { total += nums[i] } return total } func main() { // variadic parameter fmt.Printf(\u0026#34;Sum of any 1: %v\\n\u0026#34;, variadicParam(1, 2, 3)) // 6 // spread operator data := []int{1, 3, 5, 7} fmt.Printf(\u0026#34;Sum of any 2: %v\\n\u0026#34;, variadicParam(data...)) // 16 } 1.8 范围（range） 在 Go 语言中，range 关键字用于迭代数组、切片、通道（channel）、字符串或映射（map）等数据结构中的元素\nvar pow = []int{1, 2, 4, 8, 16} // 返回：(index, value) for i, v := range pow { // do v = 1, 2, ... } 并且，可以任意忽略索引或者值\nfor i, _ := range pow { // do } for _, v := range pow { // do } // 只要索引 for i := range pow { // do } 1.9 字典（Map） Go 的 Map 与 java 的 HashMap 类似。\n// 1. 仅声明 m := make(map[string]int) // 2. 声明并初始化 m := map[string]string { \u0026#34;key\u0026#34;: \u0026#34;value\u0026#34;, } m[\u0026#34;key\u0026#34;] = \u0026#34;haha\u0026#34; // 3. Map 多层嵌套 m := make(map[string]map[string]int) // m: { // \u0026#34;first\u0026#34;: { \u0026#34;v\u0026#34;: 1, ... }, // \u0026#34;second\u0026#34;: { \u0026#34;v\u0026#34;: 2, ... }, // } 1.10 枚举 Go 没有枚举类型，可以用 const 定义\ntype：和 typedef 一样 type Gender uint8 const ( MALE Gender = 1 FEMAIL Gender = 0 ) 1.11 错误处理（error） Go 内置 error，类型即为 error：\ntype error interface { Error() string } 自定义错误只需 error.New(\u0026quot;MSG\u0026quot;) 直接 New 一个错误即可，error 只是一个值，把它看错 C 语言里的 return -1/0/1 就好。\n可以使用 defer 捕获异常，使用 recover 恢复，配合使用达到 try...catch 的效果：\ndefer：延迟函数 recover：程序恢复正常 func get(i int) (ret int) { defer func() { if r := recover(); r != nil { fmt.Println(r) ret = -1 // 程序恢复正常，并且将返回值设置为 -1（不处理默认为 0） } }() y := i / (i - 2) return 22 + y; } fmt.Println(get(2)) // runtime error: integer divide by zero // -1 1.12 函数（func） 函数使用 func 声明：\n格式：func functionName(parameter TYPE) TYPE 特点：可以返回多个参数，无需创建对象/数组再组合返回 // 1. 普通函数 func f1(a int, b int) int {} func f1\u0026#39;(a, b int) int {} // 2. 多返回值 func f2() (string, int) { return \u0026#34;OK\u0026#34;, 0 } r, ok := f2() r, _ := f2() // 忽略对应值 // 3. 多返回值 - 命名返回变量，自动返回对应值 func f3() (x, y int) { var x int var y int return // 自动返回 x,y } func f3\u0026#39;() (x, y int) { return 1, 2 // 返回值覆盖，x, y 不会被返回 } 1.13 结构体和方法（struct） 结构体和方法的定义 Go 的结构体使用 type NAME struct 定义\n// 定义结构体 type Student struct { name string age int } // 定义方法：下面都可以，如果需要调用该类的字段，则需要声明变量 // * 定义结构体类型：只读 // * 定义结构体指针：可写 // func (Student) hello(person string) string // func (*Student) hello(person string) string func (stu *Student) hello(person string) string { return \u0026#34;Hello \u0026#34; + person + \u0026#34;. I am\u0026#34; + stu.name; } 同时，也可定义匿名结构体\nmyCar := struct { Make string Model string } { Make: \u0026#34;tesla\u0026#34;, Model: \u0026#34;model 3\u0026#34; } // 匿名结构体嵌套 type Car struct { Mkae string Model string Wheel struct { Raidus int Material string } } 结构体的实例化 Go 结构体的实例化有两种方式：\n1 使用 \u0026amp; 直接初始化 2 利用 new s := \u0026amp;Student{ name: \u0026#34;Tom\u0026#34;, } s := new(Student) s.hello(\u0026#34;taylor\u0026#34;) 结构体没有继承？ GO 没有继承，但可以使用组合替代\ntype User struct { name string } type Student struct { grade int User } stu := \u0026amp;Student { name: \u0026#34;Taylor\u0026#34;, grade: 2, } fmt.Println(stu.name) fmt.Println(stu.grade) 1.14 接口（interface） 在 Go 语言中，并不需要显式地声明实现了哪一个接口，只需要直接实现该接口对应的方法即可\n没有 implement 关键字，实例化成对象后，强制类型转换为接口类型（解耦） // 接口 type People interface { getName() string } type Student struct { name string age int } // 实现接口方法 func (s *Student) getName() string { return s.name } v := Student{\u0026#34;taylor\u0026#34;, 22} stu = \u0026amp;v ftm.Printfln(stu.getName()) // OK stb = v ftm.Printfln(stb.getName()) // ERROR: getName 只在 *Student（指针类型）上定义 接口可以看成是值和类型的元组 (value, type) fmt.Printf(\u0026#34;(%v, %T)\\n\u0026#34;, stu, stu) // (\u0026amp;{taylor 22}, *main.Student) 空接口表示任意类型 // 1. 接受任何类型的参数 func read(i interface{}) { // do } // 2. Map m := make(map[string]interface{}) m[\u0026#34;ni\u0026#34;] = \u0026#34;hello\u0026#34; m[\u0026#34;hao\u0026#34;] = 22 m[\u0026#34;a\u0026#34;] = [2]int{2,2} 1.15 类型判断 断言 x 不为 nil，并且存储在 x 中的值的类型为 TYPE：\nt, ok := x.(TYPE) 首先，基本类型转换，使用对应类型的转换操作即可\nvar x int = 10 var y float64 = float64(x) // 将x转为浮点数 var z int32 = int32(y) // 将y转为32位整数 其次，类型的判断，使用断言表达式：\n返回变量的值和是否匹配状态 如果类型不匹配，并且没有捕获匹配状态，则将报错 var v interface{} = \u0026#34;hahaha\u0026#34; s := v.(string) // s = \u0026#34;hahaha\u0026#34; s, ok := v.(string) // s = \u0026#34;hahaha\u0026#34;, ok = true s, ok := v.(float64) // s = 0, ok = false s := v.(float64) // panic 还可以利用 switch case 判断类型\ntype：关键字，仅用于 swatch case。 switch v := i.(type) { case int: // do case string: // do default: // no match; here v has the same type as i } 02 Generics 泛型 2.1 泛型函数 单一泛型比较简单，直接在函数后面声明 [T 类型]，其中 T 为任意名称，类型 可以是具体的内建类型，也可以是自定义的 struct。\nfunc add[T any](a, b T) T { return a + b } func main() { add(1, 2) // 3 add(1.0, 2.2) // 3.2 } 多泛型示例：\n// map func MapKeys[K string, V int](m map[K]V) []K { // do sth. } 2.2 泛型类型及其函数 type Stack[T any] struct { items []T } func (s *Stack[T]) Push(item T) { s.items = append(s.items, item) } func main() { intStack := Stack[int]{} intStack.push(1) intStack.push(2) strStack := Stack[string]{} strStack.push(\u0026#34;Hello\u0026#34;) strStack.push(\u0026#34;World\u0026#34;) } 03 Go Modules Go Modules 是 Go 语言用于管理依赖关系的官方解决方案。它的目的是简化和改进 Go 语言项目的依赖管理。\n在早期，Go 使用 GOPATH 来管理依赖包，但这种方式存在一些限制和不便。Go Modules 解决了这些问题，它的关键点包括：\n版本管理 依赖拉取：使用 go get 拉取依赖，不需要依赖于 GOPATH 的特定目录结构 版本控制 代理支持 3.1 创建项目 首先，创建一个空目录，然后使用 go mod init PROJECT 初始化，生成一个 go.mod 文件：\n$ mkdir helloWorld $ cd helloWorld $ go mod init hello $ ls go.mod $ cat go.mod module hello go 1.19.1 然后，添加 main.go，执行编译命令\n$ go build $ ls go.mod hello main.go $ ./hello Hello World~ 接着，使用 go get 安装依赖，这里以 Gin 为例：\n$ go get -u github.com/gin-gonic/gin go: downloading github.com/bytedance/sonic v1.10.2 go: downloading github.com/ugorji/go/codec v1.2.12 go: downloading github.com/go-playground/validator v9.31.0+incompatible go: downloading github.com/go-playground/validator/v10 v10.16.0 ..... $ cat go.mod module hello go 1.21.5 require ( github.com/bytedance/sonic v1.10.2 // indirect github.com/chenzhuoyu/base64x v0.0.0-20230717121745-296ad89f973d // indirect ...... ) 然后，导入依赖，修改程序：\npackage main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { // Create router. r := gin.Default() // Bind. r.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.String(http.StatusOK, \u0026#34;Hello World~\u0026#34;) }) // Run \u0026amp; Serve on 0.0.0.0:8080. r.Run(\u0026#34;:8080\u0026#34;) } 最后，go build 编译后启动服务，使用 curl 校验：\n$ curl http://localhost:8080 Hello World~ 3.2 依赖本地项目（replace） Go Modules 通常都从网上（github.com）拉取依赖，但有时候我们也需要引用到内部其他项目的依赖，需要使用 replace 替换依赖模块的路径。\n一般来说，依赖本地项目仅开发测试使用。\n例如，项目需要依赖 DDD，但是该项目目前只是测试阶段，并未推送到 github，那么可以使用 replace 指定该项目在本机的路径\nmodule example.com/myproject require ( github.com/some/DDD v1.2.3 ) replace github.com/some/DDD v1.2.3 =\u0026gt; /path/to/local/DDD 当然，replace 能替换的东西比较多，本质上就是修改依赖指向，如：\n# 1. 替换版本号 replace github.com/some/DDD v1.2.3 =\u0026gt; replace github.com/some/DDD v1.1.1 # 2. 换源 replace github.com/some/DDD v1.2.3 =\u0026gt; replace mycloud.com/some/DDD v1.1.1 04 Go Channels \u0026amp; Concurrency 4.1 Goroutines 协程 Goroutine 很简单，使用 go f(x, y, z) 即可异步执行，Goroutine 运行在同一个地址空间，因此对共享内存的访问必须同步。\nfunc f(x, y, z int) { //... } func main() { go f(x, y, z) } 4.2 Channels 管道/通道 通道是一种类型化的管道，您可以通过它使用通道运算符 \u0026lt;- 发送和接收值。\n// Channel 必须先创建 ch := make(chan int) // 向通道发送数据 ch \u0026lt;- v // Send v to channel ch. // 从通道读取数据 v := \u0026lt;-ch // Receive from ch, and // assign value to v. 默认向通道发送和接收数据时阻塞，直到发送/接收完成 从未初始化的通道（nil）读取数据，将死锁 4.3 Buffer Channels 缓冲通道 通道可以缓冲，创建通道时指定缓冲大小即可：\nch := make(chan int, 100) 普通通道默认阻塞，而缓冲通道只会在两种情况下阻塞：\n缓冲通道满时，发送阻塞 缓冲通道为空时，接收阻塞 4.4 Channel Range \u0026amp; Close 通道可以使用 Range 来遍历接收：\n// v, ok := \u0026lt;- ch // ok is false if ch has closed, or it is true ch := make(chan int, 10) // 这里只推送了 5 个，所以需要主动关闭通道 go f(5, ch) for i := range ch { // print } 发送者可以主动关闭通道（接收者不行）， 当然，通道和文件不同，通常不用关闭。\nfunc f(n int, ch chan int) { for i := 0; i \u0026lt; n; i++ { ch \u0026lt;- i + 1 } // 关闭 ch，以防 x 小于 ch 缓冲长度 close(ch) } 4.5 Select 多通道监听 上述 Channel 和 Buffer Channel 都是针对单个通道的，如果要同时接收多个通道的信息，需要使用 Select，它类似 switch 语法，只不过它用于通道监听。\nfor { select { case i, ok := \u0026lt;- ch1: // do sth. case j, ok := \u0026lt;- ch2: // do sth. } } 当 Select 监听的其中一个通道接收到数据，对执行对应的 case；如果同时多个通道都接收到消息，那么会随机选择一个（是不是有点类似 C 的 select、poll、epoll？）\nSelect 默认是阻塞等待的，但是加上 default 之后，它就变成类似 try lock 的非阻塞监听，通道有数据时读取，如果没有直接往下执行：\nselect { case i, ok := \u0026lt;- ch // do sth. default: // 从 ch 接收时会阻塞 } 4.6 只读、只写限制 声明 Channel 时，可以限制它的读写权限：\n\u0026lt;-chan T：只读通道 chan\u0026lt;- T：只写通道 func readOnly(ch \u0026lt;-chan int) { // ch can only be read from. } func wirteOnly(ch chan\u0026lt;- int) { // ch can only be write to. } func main() { ch := make(chan int) writeOnly(ch) readOnly(ch) } 05 锁 5.1 Mutex 互斥锁 互斥锁（Mutex，全称 Mutual Exclusion）是一种同步机制，用于确保在任意时刻只有一个线程能够访问共享资源，从而避免多个线程同时修改相同的数据造成的问题。\nMutex 有如下两个方法：\nsync.Lock()：加锁 sync.Unlock()：解锁 import ( \u0026#34;sync\u0026#34; ) var sharedResource int var mutex sync.Mutex func inc() { // 加锁 mutex.Lock() defer mutex.Unlock() // 在函数结束时释放锁 // 访问或修改共享资源 sharedResource++ // ... } func main() { // go inc() ... } 5.2 RWMutex 读写锁 RWMutex 读写互斥锁，它相比于普通的互斥锁 Mutex 提供了更灵活的读写控制。在 Go 语言中，RWMutex 可以同时允许多个 goroutine 获取读取锁，但在写入锁被获取时，所有的读取和写入操作都会被阻塞。\n除了有 Mutex 一样的 Lock 和 Unlock 方法，还有读写锁：\nsync.RLock()：加读锁，多个 goroutine 可同时加锁，不影响读。但如果被 Lock，则 RLock 不能再加锁，将被阻塞 sync.RUnlock()：解锁 REFERENCES [1] 官方文档. https://tour.golang.org/.\n[2] 极客兔兔. Go 语言简明教程[DB/OL]. https://geektutu.com/post/quick-golang.html.\n","permalink":"https://blog.springx.fun/posts/tech/golang-quick-guide/","summary":"00 Go 环境配置 首先，下载 Golang 安装包，地址：https://go.dev/dl/。\n接着，将 Golang 安装包解压到指定路径。\n然后，把 Go 安装路径配置到环境变量。有如下两个环境变量：\nGOROOT：可选，主要是将 $GOROOT/bin 配置到环境变量中以便直接使用 go 命令及其工具等 GOPATH：Go 1.11 之后引入 Go Modules，不再完全依赖 GOPATH 了 Go 1.11 之前，go get 下载的包会被存放在 $GOPATH/src 目录下，与项目无关 Go 1.11 之后（使用了 Go Modules），依赖包会被存放在项目的 go.mod 指定的缓存目录中，默认情况下是 $GOPATH/pkg/mod 01 Go 基础 1.1 变量 类型：放在变量名后面 变量声明：var NAME TYPE 简单变量声明：NAME := VALUE（只允许在函数内部使用，且不能用于声明静态变量） 数据类型 bool string // 不出初始化，则默认空字符串：\u0026#34;\u0026#34; int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr byte // alias for uint8 rune // alias for int32 // represents a Unicode code point float32 float64 complex64 complex128 // 复数 var x complex128 = complex(1, 2) // 1+2i var y complex128 = complex(3, 4) // 3+4i fmt.","title":"GO 语言快速入门"},{"content":"基本概念 Linux CGroup 全称 Linux Control Group， 是 Linux 内核的一个功能，用来限制，控制与分离一个进程组群的资源（如 CPU、内存、磁盘输入输出等）。\n主要提供了如下功能：\nResource limitation: 限制资源使用，比如内存使用上限以及文件系统的缓存限制。 Priority control : 优先级控制，比如：CPU 利用和磁盘 IO 吞吐。 Accounting: 一些审计或一些统计，主要目的是为了计费。 Control: 挂起进程，恢复执行进程。 一些基本的资源子系统：\nBlock IO（blkio)：限制块设备（磁盘、SSD、USB 等）的 IO 速率 CPU Set(cpuset)：限制任务能运行在哪些 CPU 核上 CPU Accounting(cpuacct)：生成 cgroup 中任务使用 CPU 的报告 CPU (CPU)：限制调度器分配的 CPU 时间 Devices (devices)：允许或者拒绝 cgroup 中任务对设备的访问 Freezer (freezer)：挂起或者重启 cgroup 中的任务 Memory (memory)：限制 cgroup 中任务使用内存的量，并生成任务当前内存的使用情况报告 Network Classifier(net_cls)：为 cgroup 中的报文设置上特定的 classid 标志，这样 tc 等工具就能根据标记对网络进行配置 Network Priority (net_prio)：对每个网络接口设置报文的优先级 perf_event：识别任务的 cgroup 成员，可以用来做性能分析 CPU 限制 创建 cgroup 首先，直接在 cgroup 对应的子资源目录下, 用 mkdir 创建一个目录，就会自动包含必要文件\n[springx.fun@ /sys/fs/cgroup/cpu]$ mkdir test [springx.fun@ /sys/fs/cgroup/cpu]$ ls test/ cgroup.clone_children cpuacct.usage cpuacct.usage_percpu_sys cpuacct.usage_user cpu.shares tasks cgroup.procs cpuacct.usage_all cpuacct.usage_percpu_user cpu.cfs_period_us cpu.stat cpuacct.stat cpuacct.usage_percpu cpuacct.usage_sys cpu.cfs_quota_us notify_on_release 然后，限制 CPU 占用率，其实就是往对应文件写入分配值。cpu.cfs_quota_us 是最大 CPU 时间片（单位微妙，us）\n-1：表示无限制 20000：在每个 100ms 的调度周期中，该 Cgroup 下的任务只能占用 CPU 时间的 20ms，超出后会被挂起，等待下一个周期的调度 [springx.fun@ /sys/fs/cgroup/cpu]$ cat test/cpu.cfs_quota_us -1 [springx.fun@ /sys/fs/cgroup/cpu]$ echo 20000 \u0026gt; test/cpu.cfs_quota_us [springx.fun@ /sys/fs/cgroup/cpu]$ cat test/cpu.cfs_quota_us 20000 运行测试 首先, 创建一个无限循环的程序:\nint main(void) { int i = 0; for(;;) i++; return 0; } 然后, 直接运行这个程序，当前是没有任何限制的，可以看到 CPU 已经占用到 100% 了:\nPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 29637 zqq 20 0 4220 632 560 R 100.0 0.0 0:07.58 a.out 接着, 将 a.out 的 PID 写入 /sys/fs/cgroup/cpu/test/tasks\n[springx.fun@ /sys/fs/cgroup/cpu]$ echo 29637 \u0026gt;\u0026gt; test/tasks 现在，可以看到 CPU 徘徊在 20% 左右\nPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 29637 zqq 20 0 4220 632 560 R 19.9 0.0 11:57.64 a.out 最后，结束 a.out 进程后, test 目录下的 tasks 的 PID 就会被清空.\n移除限制 有两个方法移出限制:\n最简单的, 结束进程即可.\n比较友好的方法, 就是将把 pid 写入到根 cgroup 的 tasks 文件即可(/sys/fs/cgroup/cpu/tasks).\n因为每个进程都属于且只属于一个 cgroup, 加入到新的 cgroup 后, 原有关系也就解除了.\n[springx.fun@ /sys/fs/cgroup/cpu]$ echo 29637 \u0026gt;\u0026gt; tasks 删除创建的 cgroup, 需要先将 tasks 都移除:\n[springx.fun@ /sys/fs/cgroup/cpu]$ rmdir test REFERENCES [1] 左耳朵耗子. DOCKER基础技术：LINUX CGROUP[EB/OL]. https://coolshell.cn/articles/17049.html, 2015-04-17.\n[2] 神仙的仙居. linux cgroups 概述[EB/OL]. https://xiezhenye.com/2013/10/linux-cgroups-%E6%A6%82%E8%BF%B0.html, 2013-10-23.\n","permalink":"https://blog.springx.fun/posts/tech/linux-cgroup/","summary":"基本概念 Linux CGroup 全称 Linux Control Group， 是 Linux 内核的一个功能，用来限制，控制与分离一个进程组群的资源（如 CPU、内存、磁盘输入输出等）。\n主要提供了如下功能：\nResource limitation: 限制资源使用，比如内存使用上限以及文件系统的缓存限制。 Priority control : 优先级控制，比如：CPU 利用和磁盘 IO 吞吐。 Accounting: 一些审计或一些统计，主要目的是为了计费。 Control: 挂起进程，恢复执行进程。 一些基本的资源子系统：\nBlock IO（blkio)：限制块设备（磁盘、SSD、USB 等）的 IO 速率 CPU Set(cpuset)：限制任务能运行在哪些 CPU 核上 CPU Accounting(cpuacct)：生成 cgroup 中任务使用 CPU 的报告 CPU (CPU)：限制调度器分配的 CPU 时间 Devices (devices)：允许或者拒绝 cgroup 中任务对设备的访问 Freezer (freezer)：挂起或者重启 cgroup 中的任务 Memory (memory)：限制 cgroup 中任务使用内存的量，并生成任务当前内存的使用情况报告 Network Classifier(net_cls)：为 cgroup 中的报文设置上特定的 classid 标志，这样 tc 等工具就能根据标记对网络进行配置 Network Priority (net_prio)：对每个网络接口设置报文的优先级 perf_event：识别任务的 cgroup 成员，可以用来做性能分析 CPU 限制 创建 cgroup 首先，直接在 cgroup 对应的子资源目录下, 用 mkdir 创建一个目录，就会自动包含必要文件","title":"Docker 之 Linux CGroup"}]